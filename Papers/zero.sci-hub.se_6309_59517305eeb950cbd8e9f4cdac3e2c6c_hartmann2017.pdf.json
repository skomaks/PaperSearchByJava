{
  "name" : "zero.sci-hub.se_6309_59517305eeb950cbd8e9f4cdac3e2c6c_hartmann2017.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "NanoCRED: A transparent framework to assess' the regulatory adequacy of ecotoxicity data for nanomaterials - Relevance and reliability revisited",
    "authors" : [ "Nanna B. Hartmann", "Marlene Ågerstrand", "Hans-Christian Holten Lützhøft", "Anders Baun" ],
    "emails" : [ "nibh@env.dtu.dk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Contents lists available at ScienceDirect\nNanoImpact\nj ourna l homepage: www. journa ls .e l sev ie r .com/nano impact\nResearch paper\nNanoCRED: A transparent framework to assess' the regulatory adequacy of ecotoxicity data for nanomaterials – Relevance and reliability revisited\nNanna B. Hartmann a,⁎, Marlene Ågerstrand b, Hans-Christian Holten Lützhøft a, Anders Baun a a Department of Environmental Engineering, Technical University of Denmark, DK-2800 Kgs. Lyngby, Denmark b Department of Environmental Science and Analytical Chemistry, Stockholm University, SE-106 91 Stockholm, Sweden\n⁎ Corresponding author. E-mail address: nibh@env.dtu.dk (N.B. Hartmann).\n1 With ‘nanomaterials’ often defined asmaterials having size range of 1–100 nm (e.g. EU, 2011).\nhttp://dx.doi.org/10.1016/j.impact.2017.03.004 2452-0748/© 2017 Elsevier B.V. All rights reserved.\na b s t r a c t a r t i c l e i n f o\nArticle history: Received 21 December 2016 Received in revised form 21 February 2017 Accepted 23 March 2017 Available online 24 March 2017\nEnvironmental hazard and risk assessment serve as the basis for regulatory decisions to protect the environment from unintentional adverse effects of chemical substances including nanomaterials. This process requires reliable and relevant environmental hazard data upon which classification and labelling can be based and Predicted NoEffect Concentration (PNEC) values canbe estimated. In a regulatory context ecotoxicological data is often recommended to be generated according to accepted and validated test guidelines, preferably also following Good Laboratory Practice. However, engineered nanomaterials are known to behave very differently in ecotoxicity tests compared to the conventional soluble chemicals, for which most guidelines were developed. Therefore nonguideline tests, or tests following modified test guidelines, can provide valuable information and should not per se be considered less adequate for regulatory use. Here we propose a framework for reliability and relevance evaluation of ecotoxicity data for nanomaterials that take into account the challenges and characterisation requirements associated with testing of these substances. The nanoCRED evaluation criteria, and accompanying guidance, were developed to be used in combination with those developed through the ‘Criteria for Reporting and Evaluating Ecotoxicity Data (CRED)’ project. This approach can accommodate all types of nanomaterials, all types of aquatic ecotoxicity studies, and qualitative as well as quantitative data evaluation requirements. Furthermore, it is practically feasible to implement and directly applicable in European as well as international regulatory frameworks.\n© 2017 Elsevier B.V. All rights reserved.\nKeywords: Nanoecotoxicology Chemical risk assessment Data evaluation REACH Predicted No-Effect Concentration"
    }, {
      "heading" : "1. Introduction",
      "text" : ""
    }, {
      "heading" : "1.1. Environmental hazard and risk assessment of nanomaterials",
      "text" : "The increasing use and anticipated environmental release of engineered nanomaterials1 from industrial and consumer applications makes environmental hazard and risk assessment of these substances of highest importance. Environmental risk assessment is a legal requirement in many countries to ensure safe production and use of chemicals and involves the gathering and critical evaluation of ecotoxicological data. For example, the United States Environmental Protection Agency (US-EPA) requires a pre-manufacture notice prior to the production or import of new chemical substances, including nanomaterials, under the Toxic Substances Control Act. Based on the submitted information, it is assessed if the chemical substance will pose a risk to human health or the environment and/or if further assessment is required (USEPA, 2015). In the European Union the procedure for chemical safety\none ormore dimensions in the\nassessment is comprised of an information gathering followed by I) an exposure assessment for deriving a Predicted Environmental Concentration (PEC) and II) a dose-response (effects) assessment leading to classification and labelling (EC, 2008; UN, 2011), identification of socalled PBT (persistent, bioaccumulative and toxic) compounds (ECHA, 2014; ECHA, 2015; ECHA, 2016; UN, 2011) and determination of a Predicted No-Effect Concentration (PNEC).\nThese procedures have been developed for conventional (soluble) chemicals, but are also considered principally applicable to nanomaterials (Aitken et al., 2011). It is well-known, however, that ecotoxicity testing of nanomaterials is not straight-forward since they behave very differently in ecotoxicity test systems compared to the conventional soluble chemicals, for which the existing test guidelines and guidance documents were intended (Pettitt and Lead, 2013). The applicability of such documents to nanomaterial testing can therefore be questioned (Khan et al., 2017; Kühnel and Nickel, 2014; Hund-Rinke et al., 2016). The fundamental reason is that nanomaterials are often insoluble or only partly soluble in water. Although they may release dissolved chemical species, they remain present as a solid phase forming a suspension of particles thatmay undergo physical transformation processes such as agglomeration and aggregation. Release of dissolved ions is well-known for nanoparticles such as ZnO, CuO, and Ag for which the\ncontribution of the dissolved species and/or the particulate form of the metals remain a topic of discussion (Skjolding et al., 2016; Notter et al., 2014; Brinch et al., 2016).\nNanomaterials thus have properties and behaviours in aquatic test systems that are different from conventional chemicals. Transformation processes, which occur before and during ecotoxicity testing, will change the exposure conditions, often violating the assumption of stable exposure concentrations during testing. It can be argued that ecotoxicity data, produced using current guideline tests, are not sufficiently sensitive (Skjolding et al., 2016) and that many of the currently established test guidelines need to be adapted or re-designed to be applicable to nanomaterials (Hund-Rinke et al., 2016; Kühnel and Nickel, 2014). For example, commonly prescribed test organisms may not be ideal for the detection of non-chemical effects of nanomaterials (Khan et al., 2017). TheOECD is a key player in this development and, although current OECD Test Guidelines for ecotoxicity are in principal applicable to nanomaterials, guidance on nano-specific testing issues is currently lacking (although under development) (Petersen et al., 2015; Hansen et al., 2017). Until these are published, regulatory assessments will continue to rely on studies performed according to existing test guidelines and lessons learned from the open scientific literature. In themeantime - and also enabling future use of existing non-guideline ecotoxicity data - a systematic and transparent method to evaluate data adequacy is needed to support data selection for environmental risk assessment of nanomaterials."
    }, {
      "heading" : "1.2. Current methods for evaluation of ecotoxicity studies for regulatory use",
      "text" : "When evaluating the regulatory adequacy of ecotoxicity studies for hazard and risk assessment purposes two elements are included in the assessment: reliability and relevance. Reliability is defined as “the inherent quality of a test report or publication relating to preferably standardized methodology and the way the experimental procedure and results are described to give evidence of the clarity and plausibility of the findings” (ECHA, 2008). Reliability is hence determined by a combined assessment of test performance, data analysis and study documentation, and all three parameters have to be sufficiently fulfilled for a study to be considered reliable. This implies that a seemingly scientifically sound study may be considered 'not assignable' if not sufficiently documented. In the same way a well-documented study is considered less reliable if the study design or test performance is inadequate or considered not to be appropriate for the tested substance. The reliability of an ecotoxicity study does not change depending on the type of hazard and risk assessment for which the study is used (Moermond et al., 2016).\nRelevance is defined as “covering the extent to which data and tests are appropriate for a particular hazard identification or risk characterization” (ECHA, 2008), meaning that the relevance of an ecotoxicity study can vary depending on its specific use. A study can for example be very relevant for an aquatic risk assessment, but less relevant for a soil risk assessment. The relevance is determined by an evaluation of e.g. the chosen endpoint, test organism, and test design in relation to the regulatory purpose of the assessment.\nIn the REACH guidance for chemical safety assessment it is recommended that the reliability of data is carefully assessed, and that this could be done using the evaluation method described by Klimisch et al. (1997). The Klimisch method offers twelve reliability evaluation criteria for acute studies and fourteen for chronic studies. However, no additional guidance on these criteria is included, nor does the method specify criteria for evaluation of relevance. A reliability evaluation according to the Klimischmethod results in one of the following reliability categories: ‘Reliable without restrictions’, ‘Reliable with restrictions’, ‘Not reliable’, and ‘Not assignable’. In most regulatory risk assessment frameworks, studies assigned reliable with or without restrictions are considered acceptable (Küster et al., 2009). The Klimisch method has been criticized for not being detailed enough to qualify as an adequate tool for evaluators, and for favouring standard test methods and GLP-\nstudies over non-standard studies from the peer-reviewed literature (Ågerstrand et al., 2011; Kase et al., 2016).\nSeveral alternative methods for evaluating the reliability and relevance of (eco)toxicity studies have been described in peer-reviewed literature (Hobbs et al., 2005; Schneider et al., 2009; Durda and Preziosi, 2000; Ågerstrand et al., 2011; Küster et al., 2009). A study by Ågerstrand et al. (2011) compared four of these methods and found, not surprisingly, that the choice of evaluation method affects the outcome of a study evaluation. Evaluation methods that lack in detail will depend more on expert judgement, which is per se not a disadvantage for the evaluation but could result in biased evaluations for example when certain aspects are prioritized differently depending on the evaluator's expertise. A structured and detailed evaluation method with well-defined criteria ensures that a similar set of criteria are considered in each evaluation, which improves consistency of evaluations, i.e. so that several evaluators arrive at the same, or at least similar, conclusion when evaluating the same study. Using such a method can also improve transparency of evaluations, thereby enabling a thorough understanding of how decisions were made for a third-party reviewer (Ågerstrand et al., 2013; Kase et al., 2016). As a response to the growing critique against the Klimisch method and general inconsistencies in data evaluation methods, the CRED (Criteria for Reporting and Evaluating Ecotoxicity Data) evaluation method was developed (Moermond et al., 2016). However, neither the Klimisch method nor the CRED evaluation method offer nano-specific guidance for evaluation of ecotoxicity studies."
    }, {
      "heading" : "1.3. Evaluation of nanomaterial ecotoxicity studies",
      "text" : "The challenges of evaluating the reliability of ecotoxicological data for nanomaterials, for use in a regulatory context, can be exemplified by the results of an assessment made by the European Commission through the NANO SUPPORT Project (EC, 2012). The project assessed the information provided in REACH registration dossiers for nanomaterials, submitted by the first registration deadline in March 2011. The Final Report of the project highlights a lack of transparency and justifications in the choice of ‘key studies’ and ‘supporting studies for the different endpoints and also describes an inconsistency in how reliability categories were appointed to different studies. For example, in one of the assessed REACH dossier, an algal growth inhibition test (performed according to the OECD 201 guideline and ISO 6341 standard) was considered ‘not reliable’ as the study setup was unsuitable for testing of nanomaterial effects. However, in another dossier this study setup was considered to be ‘reliable without restrictions' (EC, 2012).\nFor human health risk assessments there are examples of evaluation methods to assess data quality for nanomaterial studies, e.g. a two-step process for evaluation of nanotoxicity studies developed by Card and Magnuson (2010). In their procedure the first step is a reliability evaluation performed using 'ToxRTool' (Toxicological data Reliability Assessment Tool). ToxRTool was developed by Schneider et al. (2009)with the purpose of providing “comprehensive criteria and guidance for evaluations of the inherent quality of toxicological data, thus making the decision process of assigning reliability categories more transparent and more harmonised” (JRC, 2017), i.e. to assign a Klimisch category based on a transparent evaluation scheme. In the second step, a nano-score is calculated by evaluating the documentation of nano-specific characteristics such as agglomeration, surface charge and particle size. The results from the two steps are then combined into a final nano-score for the reliability of the evaluated study (Card and Magnuson, 2010).\nThis method by Card and Magnuson (2010) is directed towards human health toxicity data. Other schemes for evaluating and scoring nanomaterial data have recently been reviewed (Robinson et al., 2016) highlighting e.g. the ‘Literature Criteria Checklist’ developed by the DaNa project (DaNa, 2016) and a scheme to assess the data quality for nanotoxicity studies to be used for QSAR modelling developed by\nLubinski et al. (2013). So far, however, no method for evaluation of the regulatory adequacy of ecotoxicity data for nanomaterials exists. The aim of this paper was therefore to develop nanoCRED, a transparent and structured framework for evaluation of the reliability and relevance of nanomaterial ecotoxicity data. The intention is to provide a science based nano-specific evaluation criteria and guidance material for regulatory adequacy of aquatic (pelagic) ecotoxicity data for nanomaterial. The method aims to be on the one hand practical and flexible enough to accommodate all types of nanomaterials and all types of aquatic ecotoxicity studies, and on the other hand directly applicable to data selection for regulatory purposes."
    }, {
      "heading" : "2. Methods",
      "text" : "This evaluation method for nanomaterial ecotoxicity studies (i.e. nanoCRED) was developed largely on the basis of the method developed in the CRED project (Moermond et al., 2016), drawing on nano-specific test recommendations specified by OECD (2012), criteria included in existing evaluation tools for human health toxicity data for nanomaterials (such as those proposed by the Card and Magnuson, 2010), criteria established by the DaNa project (DaNa, 2016), and information from the open scientific literature. When adjusting and refining the criteria for evaluation of aquatic nanomaterial ecotoxicity data additional needs for data on physicochemical properties, as well as the characterisation before and during testing (OECD, 2012), were taken into account. In this method we adjusted the CRED reliability categories, as well as modify a subset of the CRED reliability criteria and accompanying guidance material. In addition, for certain relevance criteria additional nanospecific guidance was included."
    }, {
      "heading" : "3. Results",
      "text" : ""
    }, {
      "heading" : "3.1. Reliability evaluation for nanomaterials",
      "text" : "The reliability categorisation of nanomaterial ecotoxicity studies is based on a) the appropriateness of the study design for the purpose of nanomaterial testing, b) documentation provided on the study design, c) data on inherent nanomaterial properties and d) nanomaterial characterisation in the test system and during the test. Descriptions of the nanoCRED categories (nR1-nR4) are presented in Table 1.\nNano-specific considerations are provided for criterion number 1–7, 10, 12–13, 15–16, and 19 of the CRED criteria (see Table 2). Criterion number 8, 9, 11, 14, 17, 18 and 20 do not differ from the general CRED criteria. For guidance on these criteria see Moermond et al., 2016 and Supporting Information. All criteria are presented in Table 2. In contrast to the CRED evaluation method, the reliability criteria for nanomaterial ecotoxicity studies have been weighted as ‘critical’ (▲▲▲), ‘important’ (▲▲), or ‘of minor importance’ (▲) to guide the evaluator and increase the applicability of themethod (Table 2). Rationale behind theweighing is provided in the specific guidance text for each criterion. It should be kept in mind that the weighing is based on expert judgement and the current scientific understanding of nanomaterial behaviour and effects in ecotoxicity tests. The weighing may therefore be changed as a result of new information. It is therefore suggested that the evaluator scrutinize the reliability criteria and evaluate if any weighing should be adjusted due to newly emerged information on ecotoxicity testing of nanomaterials. There may also be case-specific reasons to make such changes, or, for some criteria, a possibility to choose between different pre-defined options. In these cases, such changes or choices should be justified and documented.\nThe suggested weighing is applicable only to studies on nanomaterials, and should therefore not be used in the evaluation of tests with soluble substances."
    }, {
      "heading" : "3.1.1. NanoCRED reliability criteria and guidance",
      "text" : "As for conventional chemicals the use of standard methods for ecotoxicity testing of nanomaterials is not in itself a guarantee for study reliability. Use of standard methods may ensure better and more complete documentation but does not per se ensure e.g. an appropriate study design or correct interpretation of test results (Moermond et al., 2016). This is especially true for nanomaterials. This is due to the fact that current guidelines were developed mainly for soluble chemicals and do not take into account the particulate nature of nanomaterials. Until standard methods are available explicitly for testing of nanomaterials, the use of standard methods may therefore result in lower reliability compared to non-standard tests – ormodified guideline tests. A well-considered modification of a standard method is preferred over an uncritical use of a standard method that does not account for the nano-specific physical and chemical properties. The use of standard guidelines is therefore considered to be of minor importance for reliability per se.\n2. Is the test performed under GLP conditions? (Criticality level: ▲)\nAs for standard guidelines, GLP helps to ensure reproducibility and transparency but is not in itself a guarantee for reliability. The use of GLP is therefore considered to be a criterion of minor importance for study reliability.\n3. If applicable, are validity criteria fulfilled (e.g. control survival, growth)? (Criticality level: ▲/▲▲)\nThis criterion especially applies to studies that follow guidelines or modified guidelines containing requirements regarding validity criteria. However, any study with control group mortality may indicate a test set-up problem. For nanomaterials modifications of the guidelines are often needed to accommodate the different behaviour of the nanoparticles compared to conventional soluble chemicals, for whichmost of the\ncurrently available test guidelines were originally intended. For modified guidelines the original validity criteria may not be relevant or possible to achieve. In these cases, expert judgement is required. For a description of general issues related to this criterion see Moermond et al. (2016).\n4. Are appropriate controls performed (e.g., dispersant control, metal ion control, larger than nano-sized (bulk) particles of the same chemical composition, negative and positive control)? (Criticality level: ▲▲▲)\nFor conventional chemicals it is common to use solvents to dissolve poorly soluble compounds. For nanomaterials it is not feasible and/or relevant to dissolve the particles. Instead the aim is rather to achieve a stable and homogeneous suspension (Hartmann et al., 2015). For example, when testing silver nanoparticles, the aim is not to dissolve the particles into ions and ion complexes but rather to test silver in its nanoparticulate form. Stable and homogeneous dispersions can sometimes be achieved by adding a dispersant or a stabiliser to the media. This could be a substance that adsorbs to the surface of the particle and causes electrostatic or steric stabilisation. It is important to include dispersant controls to ensure that this substance does not in itself cause toxic effects. If a dispersant has been used, but no information is provided regarding its ecotoxicity, the study is considered to be “not reliable” (nR3).\nSomenanomaterialswill dissolve partly in aqueous testingmedia during testing. This is for example the case for some silver and zinc oxide nanoparticles in standard algal and daphnia media (e.g., Cupi et al., 2015; Sørensen & Baun, 2015). Other nanomaterials, like TiO2, will not undergo dissolution under the testing conditions of ecotoxicity test. For nanomaterials which release metal ions it is important that the study also addresses the metal ion contribution to the observed toxicity. This is often done by including metal ion controls and monitoring the ion release from the nanomaterial. The key to data interpretation is then to evaluate the particle as well as the ion contributions to the observed ecotoxicological effects. Expert judgement is therefore needed to evaluate if the study is lacking critical information regarding metal ion controls.\nNanomaterials are known to introduce certain test artefacts leading to potential misinterpretation of results (Selck et al., 2016; Sørensen et al., 2015). For this reason other types of controls, may be relevant to address e.g. effects caused by endotoxins (as amaterial impurity), indirect effects (such as effects on nutrient or light availability), photoactivity, fluorescence or absorbance properties (influencing assay measurement) (Selck et al., 2016; Petersen et al., 2014). These and other potential control experiments are described in detail in Petersen et al. (2014).\nA negative control refers to test samples in pure media without the presence of nanomaterials, dispersants, etc. Mortality in the negative controls may indicate some problems with the study reliability and result in a lower reliability score (nR2 or nR3) based on expert judgement. Positive controls are useful to check the sensitivity of the test organisms\nand test performance and are often included as validity criteria in standard guideline tests (see criterion 3). If positive controls show an abnormal response this should be taken into account when evaluating the reliability of a study.\n5. Is the tested nanomaterial identifiedwith name or CAS-number? Are nanomaterial characteristics reported that allow for a clear identification of the testednanomaterial (e.g. particle size, shape, particle size distribution, surface area, coating)? Are test results reported for the relevant nanomaterial? (Criticality level: ▲▲▲)\nIt is not sufficient to specify name or CAS-number for nanomaterials as theymay cover a wide range of nanomaterials with chemical composition as the only common denominator. Nanomaterials should not only be identified from their chemical composition but also from other physico-chemical properties such as primary particle sizes, shape, crystal structure, and presence of coatings. Differences in these properties can prevent read across between two nanomaterials with the same chemical composition. Therefore, the information given in the study documentation must be consulted, where information should be available that clearly and unambiguously identifies the nanomaterial for which the ecotoxicity data has been established. The detail of this information shouldmake it possible to compare the specific tested substance with the substance forwhich e.g. the risk assessment is to be performed. If a specific tradename is given, if the material is a reference material (such as those provided by theNational Institute of Standards and Technology (NIST, 2016)) or a representative industrial nanomaterial (such as those in the Joint Research Centre Nanomaterials Repository (JRC, 2016)) additional information can be obtained from the producer/ supplier.\nThe followingparameters are considered to be theminimumcharacterisation requirements that will allow for unambiguous substance identification:\n- core chemical composition - purity - primary particle size (measured) - shape - crystal structure (if relevant) - radiolabelled (if used) - surface chemistry (e.g., coating material, functionalization if used)\nIn addition, information on surface reactivity and/or surface charge in the test media may be relevant as well as (photo)catalytic activity for some nanomaterials. Characterisation should be done using methods that are appropriate for nanomaterials. For aquatic ecotoxicity tests of some nanomaterials (like ZnO, Ag, and CuO), the water solubility ofmetal ions and related dissolution rates are parameters of high importance. To evaluate the reliability of the studies, information on dissolution of such nanomaterials must be provided. If the information is insufficient (generic and e.g. reporting only the chemical composition) the study is considered to be “not reliable” (nR3).\n6. Is the purity of the tested nanomaterial reported? This includes information on synthesis by-products aswell as synthesis catalysts and presence of other crystalline forms of the substance. And/or, is the source of the test substance trustworthy? (Criticality level: ▲▲)\nAs for conventional chemicals it is important that tested nanomaterials are of high purity (for example listed as analytical grade, ACS reagent, extra pure grade, impurities typically in the range of 0.01–1%). Impurities may be formed as a result of synthesis. For example, carbon nanotubes (CNTs)may containmetal impurities that will contribute to the overall toxicity (Petersen and Henry, 2012; Petersen et al., 2014). Also, different crystalline forms of the substance may be formed during the synthesis resulting in an unintended fraction of another crystalline form. This is for example the case for TiO2 where the anatase form may contain fractions of rutile\nand amorphous particles. If, based on expert judgement, it is evaluated that the tested nanomaterial is likely to contain impurities, but if this is not reported and addressed in the study report, the reliability of the study should be lowered. It should be noted that regulatory testing (e.g. under REACH) requires the testing of the nanomaterial as put on the market, and hence not necessarily the analytical grade nanomaterial. In such cases it is still important not to erroneously attribute the effect to the nanomaterial in itself if effects are in fact caused by e.g. metal impurities. This could be addressed in the study for example by testing a leachate/filtrate of the nanomaterial (Petersen et al., 2014).\n7. If a formulation is used or if impurities or coatings are present: Do other ingredients in the formulation, the impurities or the coatings exert an effect? Is the amount of nanomaterial in the formulation known? (Criticality level: ▲/▲▲)\nIf a formulation of a nanomaterial is used, if impurities are reported or known to be present, or if the nanomaterial is coated (for example to stabilise it in a dispersion), the potential influence hereof on the ecotoxicity should be addressed. This should clarify if the observed effects can be partly or fully attributed to the formulation, impurities, and/or the coating material. If such information is not provided, then the reliability of the study should be lowered. For uncoated nanomaterials with a high purity this is however not a critical criterion since effects are unlikely to arise from presence of impurities or coating material.\n10. Is the experimental system appropriate for the tested nanomaterial, taking into account its physico-chemical characteristics? Were measures taken to minimise losses and keep exposure stable (in quantitative and qualitative terms) throughout the duration of the test? (Criticality level: ▲▲)\nAs for conventional chemicals, the experimental system should be appropriate for the test substance in terms of e.g. vessel materials and use of methods that prevent loss of the test substance from the system (see Moermond et al., 2016). While glass is the preferred material for many conventional soluble chemicals this may not apply to nanomaterials. The test vessel should ideally be selected to minimise sorption or adherence of the nanomaterial to the surface of the container.\nFor nanomaterials it is often observed that the concentration in the water phase will decrease significantly during an aquatic ecotoxicity test due to particle aggregation/agglomeration and subsequent settling in the test vials. Stirring, shaking, use of flow through systems, and frequent media renewal are all ways of countering the loss of nanomaterials from the water phase. The overall setup of the experimental system, as well as any measures taken to avoid loss of the nanomaterial, should of course be compatible with test organism requirements (e.g. light/dark conditions, exposure route etc.). If the experimental system is considered not appropriate, the study should be considered “not reliable” (nR3).\n12. If a dispersant/stabiliser/solvent is used, is the dispersant/stabiliser/ solvent within the appropriate range and is a dispersant/stabiliser/solvent control included? (Criticality level: ▲/▲▲)\nThis criterion is linked to criterion 4. When preparing a test suspension the aim is not to dissolve the nanomaterial but rather to achieve a stable and homogeneous dispersion. To this end it can be necessary to add a dispersant/stabiliser/solvent of synthetic or natural origin. In addition, some nanomaterials are synthesized with a stabiliser, for example in the form of a capping agent, which is thus by default present in the test system. If a dispersant/stabiliser/solvent has been used the potential positive or adverse effects of this substance on the overall ecotoxicity should be addressed. Expert judgement should be applied to evaluate if concentrations are within an appropriate range. If the provided information is inadequate to\nmake such an evaluation then the reliability of the study should be lowered.\n13. Is a correct spacing between exposure concentrations applied? (Criticality level: ▲)\nDefining the actual exposure concentrations is not trivial for ecotoxicity testing of nanomaterials. Firstly, there may be a correlation between nanomaterial concentration and agglomeration behaviour (Baalousha et al., 2016), meaning that exposure changes qualitatively along the concentration-axis in a concentration-response curve. Secondly, it has been suggested that concentration may not (alone) be sufficient as a dose-descriptor and other dose-metrics (such as surface area) have been proposed (van Hoecke et al., 2009). It may therefore be very challenging to even define a ‘correct spacing’ between exposure concentrations. This criterion is therefore considered not to be critical for the reliability of ecotoxicity studies of nanomaterials. Expert judgement should however be applied to ensure that the exposure concentrations are chosen in a reasonable manner.\n15. Have analyses been performed to verify exposure, e.g. concentrations and physicochemical transformations of the nanomaterial over the duration of the test? In case of unstable exposure, has this been accounted for in the data interpretation? Is the nanomaterial dispersion procedure described in detail? (Criticality level: ▲▲▲)\nThis criterion is linked to criteria 10 and 13 above. Achieving a stable nanomaterial test suspension is a challenging task as many nanomaterials tend to agglomerate and settle in aqueous solutions and especially in test media.\nIt is known that even small changes to the sample preparation and test methodology can have a great impact on the nanomaterial behaviour in the test system and resulting effects (Cupi et al., 2016). Important factors include media composition, ionic strength, and pH. Also, it is important to know exactly how the test dispersion was prepared (including information on stock dispersion: nanomaterial nominal concentration, sonication time, sonication energy, volume and material of suspension vessel, pre-wetting steps, addition of dispersants etc.) as this will directly influence the characteristics of the test dispersion and hence the subsequent exposure conditions (Hartmann et al., 2015).\nThe introduction of a test organism is known to further destabilise the test suspension, leading to unstable exposure conditions during the tests (Hartmann et al., 2013). Asmentioned it is therefore important to monitor nanomaterial exposure over the duration of the test, quantitatively as well as qualitatively. Important parameters to monitor over the duration of the test include:\n- agglomeration state - particle size distribution - surface charge/zeta potential - ion release\nPreferably this information should be available for all tested concentrations and measured at regular intervals. For a short-term test this should be done as a minimum at the beginning and end of the test. Appropriate intervals should be established based on particle characteristics and behaviour in the test system. If for example agglomeration is known (or expected) to occur quickly then shorter intervals are required. For very stable suspensions longer intervals can be used. Also, in accordance with OECD guidance (2012) the characterisation should be carried out for the nanomaterial as dry powder, in test media, in stock suspension and in the presence of test organisms using two or more analytical methods. All measurements and characterisation should be done using methods that are appropriate for the tested nanomaterials and results reported in relevant dose metrics.\nFor conventional chemicals the OECD ecotoxicity test guidelines operates with an acceptable limit of concentration variation of max ±20% during a test (Petersen et al., 2015). If the test concentration\nvaries more than ±20% over the duration of the test this excludes the use of nominal concentrations and initial concentrations as a measure of exposure. Instead concentrations should be based on measurements throughout the test. Discussions are ongoing if such criteria are relevant for tests with nanomaterials (Petersen et al., 2015). So far there is no clear consensus on this matter. Nonetheless it is important that exposure concentrations are monitored (quantitatively and qualitatively) throughout the duration of the test and that its impact on observed effects is discussed.\n16. Is the biomass loading of the organisms in the test system within the appropriate range (b1 g/L)? (Criticality level: ▲▲)\nFor nanomaterials physical ‘overload’ phenomena are sometimes observed and it is thus important to evaluate if the effects on the organisms is caused by such testing artefacts (Sørensen et al., 2015). Overload can result physical effects, for example with particles adhering to the surface of the organisms, causing impaired movement, or blockages of swimming appendages leading to increased energy cost for maintenance (Khan et al., 2017). This requires an expert evaluation of the nanomaterial loading possibly combined with images of the biomass in the test system. A clear indication of testing artefacts caused by a high nanomaterial loading will negatively impact the reliability of the study.\n19. Is a concentration response curve observed? Is the response statistically significant? (▲/▲▲)\nRegarding concentration response curve: see explanation to criterion 13. There may be inherent characteristics on the nanomaterial test system which impedes the establishment of concentration response curves. However, whether the observed responses are statistically significant is considered to be important for study reliability. Hence, the criticality of this criterion depends on the specific type of test setup and output data. Expert judgement should be applied to evaluate the test results and the statistical significance of the observed response."
    }, {
      "heading" : "3.2. Relevance evaluation",
      "text" : "Descriptions of the nanoCRED relevance categories are presented in Table 3, and the full list of relevance criteria is presented in Table 4. Nano-specific guidance to criterion 2 and 4 are provided since these criteria relate to relevant exposure route, endpoints, andmode of action for the tested substance (i.e. nanomaterial). As opposed to reliability evaluation we do not propose a weighing of the relevance criteria as this will be context specific. However, if desired, the evaluator can, based on expert judgement, weigh each relevance criterion as either “critical”, “important” or “of minor importance”. If doing so, clear justifications should be provided to enable transparent understanding of the evaluation."
    }, {
      "heading" : "3.2.1. NanoCRED relevance criteria and guidance material",
      "text" : "For studies on nanomaterials consideration may be given to the susceptibility of the test organism to particle exposure with regard to particle uptake and biological effects. For example, the normal feeding strategy of the organism may be considered (such as food size range, uptake mechanisms and location in water column).\n4. Are the reported endpoints appropriate for the investigated effects or the mode of action of the test substance?\nFor nanomaterials with a knownmode of effect, studies that investigate these effects may be considered more relevant. At present, modes of effect are still not well understood for nanomaterials althoughmechanisms linked to the production of reactive oxygen species has been proposed (Skjolding et al., 2016). Effects may also include uptake-related non-standard endpoints and be linked to the potential for translocation of the nanomaterial away from the point of initial uptake (such as the gut) into other parts of the organism. As a better scientific understanding of effects mechanisms develop, the way in which this criterion is evaluated may change."
    }, {
      "heading" : "4. Discussion",
      "text" : "Nanomaterials are in many ways different from conventional chemicals, for which themajority of current ecotoxicological test guidelines have been developed. Nanomaterials will be present in the ecotoxicity test systems as physical entities, they undergo physical transformation processes during the test, and they are expected to have different modes of action compared to for example narcotic and polar narcotic chemicals. The test system dynamics can create a ‘black box’ testing situation due to uncontrollable changes in the exposure of the test organisms over time (e.g., Sørensen and Baun, 2015, Cupi et al., 2016). This makes it challenging to appropriately interpret the test\nresults. The field of nanoecotoxicology testing has advanced over the last decade. Existing test methods, including guideline methods, have been adapted and refined to gain more control over the test systems. As nanomaterials are likely to have different uptake and effect mechanisms, compared to conventional soluble chemicals, there might also be a need to use non-guideline test methods to elucidate potential biological effects. This creates a conflict with the current evaluation of ecotoxicity data for regulatory purposes, which largely favours guideline studies (Ågerstrand et al., 2011) and provides no nano-specific guidance.\nThe evaluation method as presented in this paper is based on an approach developed by Moermond et al. (2016) for conventional chemicals and involves an adaptation of the Klimisch method (Klimisch et al., 1997). By applying this evaluation method the reliability of guideline testmethods and non-guideline testmethods are evaluated on equal terms. Although the presented evaluation method gives clear guidance on the interpretation of the individual criteria it does not provide a ‘plug-and-play’ tool. Rather it provides a structured, transparent approach to assist expert judgement in the assessment of the regulatory adequacy of ecotoxicological studies of nanomaterials. This is a deliberate choice to ensure a flexible and case-specific implementation of the criteria for different regulatory purposes as well as ensuring the inclusion of expert judgement in the process. As the nanoCRED method only provide guidance on criteria where nano-specific considerations are warranted, it should always be combined with the CRED evaluation method (Moermond et al., 2016), where more general guidance is given. To facilitate this, a document where these two methods have been combined is provided in the Supporting Information to this paper. Using the presented criteria the evaluator has to set up a specific procedure forweighting and summarising the overall assessment of relevance and reliability. This can be done in a quantitative or qualitative manner. Also, while the method was developed for aquatic (pelagic) ecotoxicity data it may be adapted to encompass soil and sediment tests. This would, however, require that additional exposure specific aspects and analytical challenges are considered in the reliability criteria and accompanying guidance.\nA quantitative assessment can be achieved by assigning numerical values to express the level of criteria fulfilment on a scale going from ‘the study did not address this criterion at all’ to ‘satisfactory fulfilment’. This numerical value could be expressed as ‘% criteria fulfilment’ or via a pre-defined scoring system (e.g. 1–10) i.e. a continuous range or as discrete values. The criticality weighing can further be assigned a certain numerical value for ‘less important criteria’ (▲), ‘important criteria’\n(▲▲) and ‘critical criteria’ (▲▲▲), respectively. Bymultiplying the ‘fulfilment score’with the ‘criticality score’ the total weighed scores can be summed up. Pre-defined criteria for this overall score can be formulated for assigning reliability and relevance scores (nR1–nR4 and nC1–nC4) to the studies.\nAlternatively, the criteria can be used in a more qualitative manner as a general guidance for data evaluationwithout assigning quantitative scores to the study. The criteria may also be use by researchers as a checklist for ensuring transparent and complete reporting of study design, substance characterisation and results of peer-reviewed ecotoxicity studies for nanomaterials.\nAfter evaluating both the reliability and relevance of a study the study's overall adequacy for regulatory purposes can be assessed. This can be done according to the approach summarised in Fig. 1.\nIn this approach a study is considered ‘adequate for regulatory purposes’ if it is reliable without restrictions (nR1) OR reliable with restrictions (nR2) AND relevant without restrictions (nC1). This type of studies would for example be used as key studies to derive PNEC values for risk assessment purposes. A study ‘may be adequate for regulatory purposes’ if it is reliable without restrictions (nR1) OR reliable with restrictions (nR2) AND relevant with restrictions (nC2). This type of studies could for example be considered as supporting studies in a risk assessment – or could be considered for PNEC derivations in case limited data are available. Any study that is considered ‘not relevant’ (nR3) AND/OR ‘not reliable’ (nC3) OR ‘not assignable’ (nR4/nC4) is considered ‘not adequate for regulatory purposes’.\nOne should be aware that there is a difference between scientifically valid studies and studies valid for regulatory purposes. A trade-off between reliability and relevance is often present in studies found adequate for regulatory decision-making due to the need to standardize and control experimental conditions to increase the reproducibility of test results (Wickson et al., 2014). This increased reliability often undermines the environmental realism of the tests and this does, to a certain extend, affect the relevance of the test results for dose-response assessments. While this realism-control dilemma has been recognized for conventional chemicals in the REACH guidance and dealt with by using extrapolation methods to estimate PNECs, this issue has not received much attention for nanomaterials (Baun et al., 2009). When nanomaterials are tested in standard ecotoxicity tests the validity criteria of stable exposure conditions during incubation are challenged by the behaviour of nanomaterials the test systems. The links between transformed states of nanomaterials (e.g. dissolved or agglomerate forms) and biological effects are at present unknown, but transformations during testing most certainly influence the test results (Sørensen and Baun, 2015; Thit et al., 2016). The framework for evaluating the regulatory adequacy of nanomaterial ecotoxicity studies as presented in this article provides scientifically based criteria to assist regulatory decision-making. As science develops, it can be expected that also the evaluation criteria will change, e.g. due to higher demand for characterisation during testing or increased environmental realisms of test results. Also, the formation of so-called corona around nanomaterials during ecotoxicity has been explored in recent years. It is formed as the result of interaction between nanomaterials and media constituents/organisms (Nasser and Lynch, 2016), and may significantly influence the bioavailability and toxicity of particles. It is therefore at present hard to give firm recommendations on how this should be taken into account in the reliability criteria. In other words, the presented framework is not intended to be static, but will hopefully develop according to the state-of-knowledge for ecotoxicity of nanomaterials. The online tool SciRAP (Science in Risk Assessment and Policy) (www.scirap.org) can be used to access the nanoCRED evaluation method, including future updates. SciRAP is a web-based resource developed specifically to assist in the reporting and evaluation of toxicity and ecotoxicity, including nanoecotoxicity, studies (Molander et al., 2015)."
    }, {
      "heading" : "5. Conclusion",
      "text" : "In this paper a method for evaluation of the reliability and relevance of nanomaterial ecotoxicity data for regulatory purposes is presented. It includes a range of nano-specific criteria together with detail guidance that will help risk assessors when deciding on if and how a study should be used in a regulatory context. The approach is applicable to both guideline and non-guideline studies and thereby deviating significantly from the currently used Klimisch approach, which inherently favours the use of guideline tests performed according to GLP. This evaluation framework may contribute to improved risk assessments of nanomaterials by enabling a data selection focussed at regulatory reliability and relevance while at the same time promoting transparency in the evaluation process.\nConflict of interest\nThe authors declare no conflicts of interests."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work is part of the project ENVNANO (Environmental Effects and Risk Evaluation of Engineered Nanoparticles) supported by the European Research Council (grant no. 281579). The Danish Environmental Protection Agency is furthermore thanked for funding through the NanoDen project (Environmental Project No. 1594, 2014). Marlene Ågerstrands contribution was funded by the foundation “Oscar och Lili Lamms Minne”."
    }, {
      "heading" : "Appendix A. Supplementary Information",
      "text" : "Supplementary Information ('Manual for the practical use of nanoCRED') to this article can be found online at http://dx.doi.org/10. 1016/j.impact.2017.03.004."
    } ],
    "references" : [ {
      "title" : "Comparison of four different methods for reliability evaluation of ecotoxicity data: a case study of non-standard test data used in environmental risk assessments of pharmaceutical substances",
      "author" : [ "Ågerstrand", "Marlene", "Breitholtz", "Magnus", "Rudén", "Christina" ],
      "venue" : "Environ. Sci. Eur",
      "citeRegEx" : "Ågerstrand et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ågerstrand et al\\.",
      "year" : 2011
    }, {
      "title" : "Bad reporting or bad science? Systematic data evaluation as a means to improve the use of peer-reviewed studies in risk assessments of chemicals",
      "author" : [ "Ågerstrand", "Marlene", "Edvardsson", "Linnéa", "Rudén", "Christina" ],
      "venue" : "Hum. Ecol. Risk Assess. Int. J",
      "citeRegEx" : "Ågerstrand et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Ågerstrand et al\\.",
      "year" : 2013
    }, {
      "title" : "Specific Advice on Exposure Assessment and Hazard/Risk Characterisation for Nanomaterials under REACH (RIP-oN 3)-Final Project Report",
      "author" : [ "R.A. Aitken", "A. Bassan", "S. Friedrichs", "S.M. Hankin", "S.F. Hansen", "J. Holmqvist", "S.A.K. Peters", "C.A. Poland", "C.L. Tran" ],
      "venue" : "European Commission Available from:. http://ec.europa.eu/environment/ chemicals/nanotech/pdf/report_ripon3.pdf",
      "citeRegEx" : "Aitken et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Aitken et al\\.",
      "year" : 2011
    }, {
      "title" : "The concentration-dependent behavior of nanoparticles",
      "author" : [ "M. Baalousha", "M. Sikder", "A. Prasad", "J.R. Lead", "R. Merrifield", "G.T. Chandler" ],
      "venue" : "Environ. Chem",
      "citeRegEx" : "Baalousha et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Baalousha et al\\.",
      "year" : 2016
    }, {
      "title" : "Setting the limits for engineered nanoparticles in European surface waters–are current approaches appropriate",
      "author" : [ "A. Baun", "N.B. Hartmann", "K.D. Grieger", "S.F. Hansen" ],
      "venue" : "J. Environ. Monit",
      "citeRegEx" : "Baun et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Baun et al\\.",
      "year" : 2009
    }, {
      "title" : "EU regulation of nanobiocides: challenges in implementing the biocidal product regulation (BPR)",
      "author" : [ "A. Brinch", "S.F. Hansen", "N.B. Hartmann", "A. Baun" ],
      "venue" : null,
      "citeRegEx" : "Brinch et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Brinch et al\\.",
      "year" : 2016
    }, {
      "title" : "A method to assess the quality of studies that examine the toxicity of engineered nanomaterials",
      "author" : [ "J.W. Card", "B.A. Magnuson" ],
      "venue" : "Int. J. Toxicol",
      "citeRegEx" : "Card and Magnuson,? \\Q2010\\E",
      "shortCiteRegEx" : "Card and Magnuson",
      "year" : 2010
    }, {
      "title" : "The influence of natural organic matter and aging on suspension stability in guideline toxicity testing of ZnO, TiO2, and Ag nanoparticles with Daphnia magna",
      "author" : [ "D. Cupi", "N.B. Hartmann", "A. Baun" ],
      "venue" : "Environ. Toxicol. Chem",
      "citeRegEx" : "Cupi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cupi et al\\.",
      "year" : 2015
    }, {
      "title" : "Influence of pH and media composition on suspension stability of silver, zinc oxide, and titanium dioxide nanoparticles and immobilization of Daphnia magna under guideline testing conditions",
      "author" : [ "D. Cupi", "N.B. Hartmann", "A. Baun" ],
      "venue" : "Ecotoxicol. Environ. Saf. 127:144–152",
      "citeRegEx" : "Cupi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Cupi et al\\.",
      "year" : 2016
    }, {
      "title" : "Data quality evaluation of toxicological studies used to derive ecotoxicological benchmarks",
      "author" : [ "Durda", "Judi L", "Preziosi", "Damian V" ],
      "venue" : "Hum. Ecol. Risk. Assess",
      "citeRegEx" : "Durda et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Durda et al\\.",
      "year" : 2000
    }, {
      "title" : "Techniques and protocols",
      "author" : [ "D. Gilliland", "F. Pianella", "J.M. Riego Sintes" ],
      "venue" : null,
      "citeRegEx" : "Gilliland et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gilliland et al\\.",
      "year" : 2015
    }, {
      "title" : "Evaluation of criteria",
      "author" : [ "Hobbs", "Dustin A", "Warne", "Michael St J", "Markich", "Scott J" ],
      "venue" : "J. Toxicol. Environ. Health B",
      "citeRegEx" : "Hobbs et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Hobbs et al\\.",
      "year" : 2005
    }, {
      "title" : "Criteria for Reporting and Evaluat",
      "author" : [ "R. Kase", "M. Korkaric", "I. Werner", "M. Ågerstrand" ],
      "venue" : null,
      "citeRegEx" : "Kase et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kase et al\\.",
      "year" : 2016
    }, {
      "title" : "Are standardized test guidelines",
      "author" : [ "F.R. Khan", "K. Syberg", "A. Palmqvist" ],
      "venue" : null,
      "citeRegEx" : "Khan et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Khan et al\\.",
      "year" : 2017
    }, {
      "title" : "A systematic approach for evaluating",
      "author" : [ "1948–1950. Klimisch", "H.-J", "M. Andreae", "U. Tillmann" ],
      "venue" : null,
      "citeRegEx" : "Klimisch et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Klimisch et al\\.",
      "year" : 1997
    }, {
      "title" : "The OECD expert meeting on ecotoxicology and environmen",
      "author" : [ "Pharmacol" ],
      "venue" : null,
      "citeRegEx" : "Pharmacol.,? \\Q1996\\E",
      "shortCiteRegEx" : "Pharmacol.",
      "year" : 1996
    }, {
      "title" : "Regulatory demands on data quality",
      "author" : [ "S. Schmitz", "E. Thumm", "B. Rechenberg" ],
      "venue" : null,
      "citeRegEx" : "Schmitz et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Schmitz et al\\.",
      "year" : 2009
    }, {
      "title" : "Evaluation criteria for the quality of published experimental data on nanomaterials and their usefulness for QSARmodelling",
      "author" : [ "L. Lubinski", "P. Urbaszek", "A. Gajewicz", "M.T.D. Cronin", "S.J. Enoch", "J.C. Madden", "D. Leszczynska", "J. Leszczynski", "T. Puzyn" ],
      "venue" : "SAR QSAR Environ. Res",
      "citeRegEx" : "Lubinski et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lubinski et al\\.",
      "year" : 2013
    }, {
      "title" : "CRED: criteria for reporting and evaluating ecotoxicity data",
      "author" : [ "C. Moermond", "R. Kase", "M. Korkaric", "M. Ågerstrand" ],
      "venue" : "Environ. Toxicol. Chem",
      "citeRegEx" : "Moermond et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Moermond et al\\.",
      "year" : 2016
    }, {
      "title" : "Science in Risk Assessment and Policy (SciRAP): an online resource for evaluating and reporting in vivo (eco) toxicity studies",
      "author" : [ "L. Molander", "M. Ågerstrand", "A. Beronius", "A. Hanberg", "C. Rudén" ],
      "venue" : "Hum. Ecol. Risk Assess. Int. J",
      "citeRegEx" : "Molander et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Molander et al\\.",
      "year" : 2015
    }, {
      "title" : "Secreted protein eco-corona mediates uptake and impacts of polystyrene nanoparticles on Daphnia magna",
      "author" : [ "F. Nasser", "I. Lynch" ],
      "venue" : "J. Proteome",
      "citeRegEx" : "Nasser and Lynch,? \\Q2016\\E",
      "shortCiteRegEx" : "Nasser and Lynch",
      "year" : 2016
    }, {
      "title" : "Are nanosized or dissolved metals more toxic in the environment? A meta-analysis",
      "author" : [ "Notter", "D.a", "D.M. Mitrano", "B. Nowack" ],
      "venue" : "Environ. Toxicol. Chem",
      "citeRegEx" : "Notter et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Notter et al\\.",
      "year" : 2014
    }, {
      "title" : "Methodological considerations for testing the ecotoxicity of carbon nanotubes and fullerenes: review",
      "author" : [ "E.J. Petersen", "T.B. Henry" ],
      "venue" : "Environ. Toxicol. Chem",
      "citeRegEx" : "Petersen and Henry,? \\Q2012\\E",
      "shortCiteRegEx" : "Petersen and Henry",
      "year" : 2012
    }, {
      "title" : "Identification and avoidance of potential artifacts and misinterpretations in nanomaterial ecotoxicity measurements",
      "author" : [ "E.J. Petersen", "T.B. Henry", "J. Zhao", "R.I. MacCuspie", "T.L. Kirschling", "M.A. Dobrovolskaia", "V. Hackley", "B. Xing", "J.C. White" ],
      "venue" : "Environ. Sci. Technol",
      "citeRegEx" : "Petersen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Petersen et al\\.",
      "year" : 2014
    }, {
      "title" : "Adapting OECD aquatic toxicity tests for use with manufactured nanomaterials: key issues and consensus recommendations",
      "author" : [ "E.J. Petersen", "S.A. Diamond", "A.J. Kennedy", "G.G. Goss", "K. Ho", "J. Lead", "S.K. Hanna", "N.B. Hartmann", "K. Hund-Rinke", "B. Mader", "N. Manier", "P. Pandard", "E. Salinas", "P. Sayre" ],
      "venue" : "Environ. Sci. Technol",
      "citeRegEx" : "Petersen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Petersen et al\\.",
      "year" : 2015
    }, {
      "title" : "Lead, J.R., 2013.Minimumphysicochemical characterisation requirements for nanomaterial regulation",
      "author" : [ "M.E. Pettitt" ],
      "venue" : "Environ. Int",
      "citeRegEx" : "Pettitt,? \\Q2013\\E",
      "shortCiteRegEx" : "Pettitt",
      "year" : 2013
    }, {
      "title" : "How should the completeness and quality of curated nanomaterial data be evaluated",
      "author" : [ "R.L.M. Robinson", "I. Lynch", "W. Peijnenburg", "J. Rumble", "F. Klaessig", "C. Marquardt", "H. Rauscher", "T. Puzyn", "R. Purian", "C. Åberg", "S. Karcher" ],
      "venue" : "Nano 8",
      "citeRegEx" : "Robinson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Robinson et al\\.",
      "year" : 2016
    }, {
      "title" : "ToxRTool’, a new tool to assess the reliability of toxicological data",
      "author" : [ "Schneider", "Klaus", "Schwarz", "Markus", "Burkholder", "Iris", "Kopp-Schneider", "Annette", "Edler", "Lutz", "Kinsner-Ovaskainen", "Agnieszka", "Hartung", "Thomas", "Hoffmann", "Sebastian" ],
      "venue" : "Toxicol. Lett",
      "citeRegEx" : "Schneider et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2009
    }, {
      "title" : "Nanomaterials in the aquatic environment: a European Union–United States perspective on the status of ecotoxicity testing, research priorities, and challenges ahead",
      "author" : [ "H. Selck", "R.D. Handy", "T.F. Fernandes", "S.J. Klaine", "E.J. Petersen" ],
      "venue" : "Environ. Toxicol. Chem",
      "citeRegEx" : "Selck et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Selck et al\\.",
      "year" : 2016
    }, {
      "title" : "A critical review of aquatic ecotoxicity testing of nanoparticles-the quest for disclosing nanoparticle effects",
      "author" : [ "L.M. Skjolding", "S.N. Sørensen", "N.B. Hartmann", "R. Hjorth", "S.F. Hansen", "A. Baun" ],
      "venue" : "Angew. Chem. Int. Ed",
      "citeRegEx" : "Skjolding et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Skjolding et al\\.",
      "year" : 2016
    }, {
      "title" : "Controlling silver nanoparticle exposure in algal toxicity testing – a matter of timing",
      "author" : [ "S.N. Sørensen", "A. Baun" ],
      "venue" : "Nanotoxicology",
      "citeRegEx" : "Sørensen and Baun,? \\Q2015\\E",
      "shortCiteRegEx" : "Sørensen and Baun",
      "year" : 2015
    }, {
      "title" : "Nanoparticle ecotoxicity—physical and/or chemical effects",
      "author" : [ "S.N. Sørensen", "R. Hjorth", "C.G. Delgado", "N.B. Hartmann", "A. Baun" ],
      "venue" : "Integr. Environ. Assess. Manag",
      "citeRegEx" : "Sørensen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sørensen et al\\.",
      "year" : 2015
    }, {
      "title" : "Acute toxicity of copper oxide nanoparticles to Daphnia magna under different test conditions",
      "author" : [ "A. Thit", "K. Huggins", "H. Selck", "A. Baun" ],
      "venue" : "Toxicol. Environ. Chem",
      "citeRegEx" : "Thit et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Thit et al\\.",
      "year" : 2016
    }, {
      "title" : "Balancing scientific tensions",
      "author" : [ "F. Wickson", "N.B. Hartmann", "R. Hjorth", "S.F. Hansen", "B. Wynne", "A. Baun" ],
      "venue" : "Nat. Nanotechnol",
      "citeRegEx" : "Wickson et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Wickson et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "These procedures have been developed for conventional (soluble) chemicals, but are also considered principally applicable to nanomaterials (Aitken et al., 2011).",
      "startOffset" : 139,
      "endOffset" : 160
    }, {
      "referenceID" : 13,
      "context" : "The applicability of such documents to nanomaterial testing can therefore be questioned (Khan et al., 2017; Kühnel and Nickel, 2014; Hund-Rinke et al., 2016).",
      "startOffset" : 88,
      "endOffset" : 157
    }, {
      "referenceID" : 29,
      "context" : "contribution of the dissolved species and/or the particulate form of the metals remain a topic of discussion (Skjolding et al., 2016; Notter et al., 2014; Brinch et al., 2016).",
      "startOffset" : 109,
      "endOffset" : 175
    }, {
      "referenceID" : 21,
      "context" : "contribution of the dissolved species and/or the particulate form of the metals remain a topic of discussion (Skjolding et al., 2016; Notter et al., 2014; Brinch et al., 2016).",
      "startOffset" : 109,
      "endOffset" : 175
    }, {
      "referenceID" : 5,
      "context" : "contribution of the dissolved species and/or the particulate form of the metals remain a topic of discussion (Skjolding et al., 2016; Notter et al., 2014; Brinch et al., 2016).",
      "startOffset" : 109,
      "endOffset" : 175
    }, {
      "referenceID" : 29,
      "context" : "It can be argued that ecotoxicity data, produced using current guideline tests, are not sufficiently sensitive (Skjolding et al., 2016) and that many of the currently established test guidelines need to be adapted or re-designed to be applicable to nanomaterials (Hund-Rinke et al.",
      "startOffset" : 111,
      "endOffset" : 135
    }, {
      "referenceID" : 13,
      "context" : "For example, commonly prescribed test organisms may not be ideal for the detection of non-chemical effects of nanomaterials (Khan et al., 2017).",
      "startOffset" : 124,
      "endOffset" : 143
    }, {
      "referenceID" : 24,
      "context" : "TheOECD is a key player in this development and, although current OECD Test Guidelines for ecotoxicity are in principal applicable to nanomaterials, guidance on nano-specific testing issues is currently lacking (although under development) (Petersen et al., 2015; Hansen et al., 2017).",
      "startOffset" : 240,
      "endOffset" : 284
    }, {
      "referenceID" : 18,
      "context" : "The reliability of an ecotoxicity study does not change depending on the type of hazard and risk assessment for which the study is used (Moermond et al., 2016).",
      "startOffset" : 136,
      "endOffset" : 159
    }, {
      "referenceID" : 0,
      "context" : "The Klimisch method has been criticized for not being detailed enough to qualify as an adequate tool for evaluators, and for favouring standard test methods and GLPstudies over non-standard studies from the peer-reviewed literature (Ågerstrand et al., 2011; Kase et al., 2016).",
      "startOffset" : 232,
      "endOffset" : 276
    }, {
      "referenceID" : 12,
      "context" : "The Klimisch method has been criticized for not being detailed enough to qualify as an adequate tool for evaluators, and for favouring standard test methods and GLPstudies over non-standard studies from the peer-reviewed literature (Ågerstrand et al., 2011; Kase et al., 2016).",
      "startOffset" : 232,
      "endOffset" : 276
    }, {
      "referenceID" : 11,
      "context" : "Several alternative methods for evaluating the reliability and relevance of (eco)toxicity studies have been described in peer-reviewed literature (Hobbs et al., 2005; Schneider et al., 2009; Durda and Preziosi, 2000; Ågerstrand et al., 2011; Küster et al., 2009).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 27,
      "context" : "Several alternative methods for evaluating the reliability and relevance of (eco)toxicity studies have been described in peer-reviewed literature (Hobbs et al., 2005; Schneider et al., 2009; Durda and Preziosi, 2000; Ågerstrand et al., 2011; Küster et al., 2009).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 0,
      "context" : "Several alternative methods for evaluating the reliability and relevance of (eco)toxicity studies have been described in peer-reviewed literature (Hobbs et al., 2005; Schneider et al., 2009; Durda and Preziosi, 2000; Ågerstrand et al., 2011; Küster et al., 2009).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 1,
      "context" : "Using such a method can also improve transparency of evaluations, thereby enabling a thorough understanding of how decisions were made for a third-party reviewer (Ågerstrand et al., 2013; Kase et al., 2016).",
      "startOffset" : 162,
      "endOffset" : 206
    }, {
      "referenceID" : 12,
      "context" : "Using such a method can also improve transparency of evaluations, thereby enabling a thorough understanding of how decisions were made for a third-party reviewer (Ågerstrand et al., 2013; Kase et al., 2016).",
      "startOffset" : 162,
      "endOffset" : 206
    }, {
      "referenceID" : 18,
      "context" : "As a response to the growing critique against the Klimisch method and general inconsistencies in data evaluation methods, the CRED (Criteria for Reporting and Evaluating Ecotoxicity Data) evaluation method was developed (Moermond et al., 2016).",
      "startOffset" : 220,
      "endOffset" : 243
    }, {
      "referenceID" : 6,
      "context" : "The results from the two steps are then combined into a final nano-score for the reliability of the evaluated study (Card and Magnuson, 2010).",
      "startOffset" : 116,
      "endOffset" : 141
    }, {
      "referenceID" : 26,
      "context" : "Other schemes for evaluating and scoring nanomaterial data have recently been reviewed (Robinson et al., 2016) highlighting e.",
      "startOffset" : 87,
      "endOffset" : 110
    }, {
      "referenceID" : 18,
      "context" : "nanoCRED) was developed largely on the basis of the method developed in the CRED project (Moermond et al., 2016), drawing on nano-specific test recommendations specified by OECD (2012), criteria included in existing evaluation tools for human health toxicity data for nanomaterials (such as those proposed by the Card and Magnuson, 2010), criteria established by the DaNa project (DaNa, 2016), and information from the open scientific literature.",
      "startOffset" : 89,
      "endOffset" : 112
    }, {
      "referenceID" : 18,
      "context" : "an appropriate study design or correct interpretation of test results (Moermond et al., 2016).",
      "startOffset" : 70,
      "endOffset" : 93
    }, {
      "referenceID" : 28,
      "context" : "Nanomaterials are known to introduce certain test artefacts leading to potential misinterpretation of results (Selck et al., 2016; Sørensen et al., 2015).",
      "startOffset" : 110,
      "endOffset" : 153
    }, {
      "referenceID" : 31,
      "context" : "Nanomaterials are known to introduce certain test artefacts leading to potential misinterpretation of results (Selck et al., 2016; Sørensen et al., 2015).",
      "startOffset" : 110,
      "endOffset" : 153
    }, {
      "referenceID" : 28,
      "context" : "effects caused by endotoxins (as amaterial impurity), indirect effects (such as effects on nutrient or light availability), photoactivity, fluorescence or absorbance properties (influencing assay measurement) (Selck et al., 2016; Petersen et al., 2014).",
      "startOffset" : 209,
      "endOffset" : 252
    }, {
      "referenceID" : 23,
      "context" : "effects caused by endotoxins (as amaterial impurity), indirect effects (such as effects on nutrient or light availability), photoactivity, fluorescence or absorbance properties (influencing assay measurement) (Selck et al., 2016; Petersen et al., 2014).",
      "startOffset" : 209,
      "endOffset" : 252
    }, {
      "referenceID" : 22,
      "context" : "For example, carbon nanotubes (CNTs)may containmetal impurities that will contribute to the overall toxicity (Petersen and Henry, 2012; Petersen et al., 2014).",
      "startOffset" : 109,
      "endOffset" : 158
    }, {
      "referenceID" : 23,
      "context" : "For example, carbon nanotubes (CNTs)may containmetal impurities that will contribute to the overall toxicity (Petersen and Henry, 2012; Petersen et al., 2014).",
      "startOffset" : 109,
      "endOffset" : 158
    }, {
      "referenceID" : 23,
      "context" : "This could be addressed in the study for example by testing a leachate/filtrate of the nanomaterial (Petersen et al., 2014).",
      "startOffset" : 100,
      "endOffset" : 123
    }, {
      "referenceID" : 3,
      "context" : "Firstly, there may be a correlation between nanomaterial concentration and agglomeration behaviour (Baalousha et al., 2016), meaning that exposure changes qualitatively along the concentration-axis in a concentration-response curve.",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 8,
      "context" : "It is known that even small changes to the sample preparation and test methodology can have a great impact on the nanomaterial behaviour in the test system and resulting effects (Cupi et al., 2016).",
      "startOffset" : 178,
      "endOffset" : 197
    }, {
      "referenceID" : 24,
      "context" : "For conventional chemicals the OECD ecotoxicity test guidelines operates with an acceptable limit of concentration variation of max ±20% during a test (Petersen et al., 2015).",
      "startOffset" : 151,
      "endOffset" : 174
    }, {
      "referenceID" : 24,
      "context" : "Discussions are ongoing if such criteria are relevant for tests with nanomaterials (Petersen et al., 2015).",
      "startOffset" : 83,
      "endOffset" : 106
    }, {
      "referenceID" : 31,
      "context" : "For nanomaterials physical ‘overload’ phenomena are sometimes observed and it is thus important to evaluate if the effects on the organisms is caused by such testing artefacts (Sørensen et al., 2015).",
      "startOffset" : 176,
      "endOffset" : 199
    }, {
      "referenceID" : 13,
      "context" : "Overload can result physical effects, for example with particles adhering to the surface of the organisms, causing impaired movement, or blockages of swimming appendages leading to increased energy cost for maintenance (Khan et al., 2017).",
      "startOffset" : 219,
      "endOffset" : 238
    }, {
      "referenceID" : 29,
      "context" : "At present, modes of effect are still not well understood for nanomaterials althoughmechanisms linked to the production of reactive oxygen species has been proposed (Skjolding et al., 2016).",
      "startOffset" : 165,
      "endOffset" : 189
    }, {
      "referenceID" : 0,
      "context" : "This creates a conflict with the current evaluation of ecotoxicity data for regulatory purposes, which largely favours guideline studies (Ågerstrand et al., 2011) and provides no nano-specific guidance.",
      "startOffset" : 137,
      "endOffset" : 162
    }, {
      "referenceID" : 14,
      "context" : "(2016) for conventional chemicals and involves an adaptation of the Klimisch method (Klimisch et al., 1997).",
      "startOffset" : 84,
      "endOffset" : 107
    }, {
      "referenceID" : 18,
      "context" : "As the nanoCRED method only provide guidance on criteria where nano-specific considerations are warranted, it should always be combined with the CRED evaluation method (Moermond et al., 2016), where more general guidance is given.",
      "startOffset" : 168,
      "endOffset" : 191
    }, {
      "referenceID" : 33,
      "context" : "A trade-off between reliability and relevance is often present in studies found adequate for regulatory decision-making due to the need to standardize and control experimental conditions to increase the reproducibility of test results (Wickson et al., 2014).",
      "startOffset" : 235,
      "endOffset" : 257
    }, {
      "referenceID" : 4,
      "context" : "While this realism-control dilemma has been recognized for conventional chemicals in the REACH guidance and dealt with by using extrapolation methods to estimate PNECs, this issue has not received much attention for nanomaterials (Baun et al., 2009).",
      "startOffset" : 230,
      "endOffset" : 249
    }, {
      "referenceID" : 30,
      "context" : "dissolved or agglomerate forms) and biological effects are at present unknown, but transformations during testing most certainly influence the test results (Sørensen and Baun, 2015; Thit et al., 2016).",
      "startOffset" : 156,
      "endOffset" : 200
    }, {
      "referenceID" : 32,
      "context" : "dissolved or agglomerate forms) and biological effects are at present unknown, but transformations during testing most certainly influence the test results (Sørensen and Baun, 2015; Thit et al., 2016).",
      "startOffset" : 156,
      "endOffset" : 200
    }, {
      "referenceID" : 20,
      "context" : "It is formed as the result of interaction between nanomaterials and media constituents/organisms (Nasser and Lynch, 2016), and may significantly influence the bioavailability and toxicity of particles.",
      "startOffset" : 97,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "SciRAP is a web-based resource developed specifically to assist in the reporting and evaluation of toxicity and ecotoxicity, including nanoecotoxicity, studies (Molander et al., 2015).",
      "startOffset" : 160,
      "endOffset" : 183
    } ],
    "year" : 2017,
    "abstractText" : "Article history: Received 21 December 2016 Received in revised form 21 February 2017 Accepted 23 March 2017 Available online 24 March 2017 Environmental hazard and risk assessment serve as the basis for regulatory decisions to protect the environment from unintentional adverse effects of chemical substances including nanomaterials. This process requires reliable and relevant environmental hazard data upon which classification and labelling can be based and Predicted NoEffect Concentration (PNEC) values canbe estimated. In a regulatory context ecotoxicological data is often recommended to be generated according to accepted and validated test guidelines, preferably also following Good Laboratory Practice. However, engineered nanomaterials are known to behave very differently in ecotoxicity tests compared to the conventional soluble chemicals, for which most guidelines were developed. Therefore nonguideline tests, or tests following modified test guidelines, can provide valuable information and should not per se be considered less adequate for regulatory use. Here we propose a framework for reliability and relevance evaluation of ecotoxicity data for nanomaterials that take into account the challenges and characterisation requirements associated with testing of these substances. The nanoCRED evaluation criteria, and accompanying guidance, were developed to be used in combination with those developed through the ‘Criteria for Reporting and Evaluating Ecotoxicity Data (CRED)’ project. This approach can accommodate all types of nanomaterials, all types of aquatic ecotoxicity studies, and qualitative as well as quantitative data evaluation requirements. Furthermore, it is practically feasible to implement and directly applicable in European as well as international regulatory frameworks. © 2017 Elsevier B.V. All rights reserved.",
    "creator" : "Elsevier"
  }
}