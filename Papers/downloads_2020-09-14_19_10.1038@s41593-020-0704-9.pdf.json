{
  "name" : "downloads_2020-09-14_19_10.1038@s41593-020-0704-9.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Dense neuronal reconstruction through X-ray holographic nano-tomography",
    "authors" : [ "Aaron T. Kuan", "Jasper S. Phelps" ],
    "emails" : [ "joitapac@esrf.eu;", "wei-chung_lee@hms.harvard.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Technical RepoRT https://doi.org/10.1038/s41593-020-0704-9\n1Department of Neurobiology, Harvard Medical School, Boston, MA, USA. 2Program in Neuroscience, Harvard University, Boston, MA, USA. 3Department of Genetics, Harvard Medical School, Boston, MA, USA. 4Department of Physiology and Biophysics, University of Washington, Seattle, WA, USA. 5HHMI Janelia Research Campus, Ashburn, VA, USA. 6ESRF, The European Synchrotron, Grenoble, France. 7F.M. Kirby Neurobiology Center, Boston Children’s Hospital, Harvard Medical School, Boston, MA, USA. 8These authors contributed equally: Aaron T. Kuan, Jasper S. Phelps. ✉e-mail: joitapac@esrf.eu; wei-chung_lee@hms.harvard.edu\nMapping the structure of the nervous system provides a foun-dation for understanding its function. However, compre-hensive mapping at the scale of neuronal circuits requires imaging with both high resolution and large fields of view (FOVs). EM has sufficient resolution, but obtaining three-dimensional (3D) EM volumes of even small neural circuits requires collecting millions of EM images across thousands of thin sections and, therefore, can be prohibitively costly in terms of time and resources1–4. Conventional LM is limited in spatial resolution due to the diffraction limit (~250 nm, although super-resolution5,6 and expansion microscopy7,8 techniques can exceed this) and, thus, requires sparse fluorescent labeling to resolve individual cells. Furthermore, visible light does not easily penetrate tissue, requiring physical sectioning or tissue clearing for thick samples (>1 mm). As a result, the comprehensive set of cells comprising most neural circuits remains unknown. Thus, an imaging modality capable of resolving densely packed neurons over millimeter-scale tissue volumes could enable more complete characterization and understanding of neural circuits.\nHigh-energy X-rays (>10 keV) have the potential to image thick specimens with high spatial resolution owing to their strong penetration power and sub-nanometer wavelength. Attenuation-based X-ray microscopy techniques offer volumetric imaging of millimeter-scale samples, but these techniques rely on sparse labeling owing to limited contrast9. Phase-contrast imaging techniques, such as X-ray interferometry10–12, X-ray ptychography13,14, single-distance free-space propagation imaging15,16 and X-ray holography17–21, have brought substantial improvements to image quality but have yet to achieve the combination of resolution, FOV and contrast required for reconstruction of densely stained neuronal morphologies. Thus, until now, tracing of individual neuron morphologies from X-ray image data has been possible only through sparse labeling9,16,22.\nHere we demonstrate X-ray imaging of densely stained neural tissue at resolutions down to 87 nm across millimeter-sized volumes, enabling reconstruction of the main branching patterns of neurons within the imaged volume. To achieve this, we employed X-ray holographic nano-tomography (XNH)23,24 and made improvements by customizing sample preparation, incorporating cryogenic imaging and optimizing phase retrieval approaches. We show that targeted EM can be used to measure synaptic connectivity of neurons previously reconstructed via XNH. We used this correlative approach in mouse cortex to quantify how the balance of inhibitory and excitatory inputs onto apical dendrites (ADs) varies by pyramidal cell type (that is, layer). XNH imaging also allows reconstruction of structures that are difficult to physically section, such as the adult Drosophila leg. We present an XNH dataset of an intact leg in which we reconstructed internal structures, such as muscle fibers and sensory receptors, and traced their associated motor and sensory neurons back to circuits in the fly’s central nervous system. Finally, we applied a convolutional neural network (CNN) to automatically reconstruct neurons from XNH data. These results establish XNH as a key technique for biological imaging, which bridges the gap between LM and EM (Fig. 1a) to enable dense reconstruction of neuronal morphologies on the scale of neuronal circuits."
    }, {
      "heading" : "Results",
      "text" : "XNH imaging of central and peripheral nervous systems. We imaged samples of mouse cortex and adult Drosophila brain, ventral nerve cord and leg at the ID16A beamline of the European Synchrotron Radiation Facility (ESRF). The positioning of the sample relative to the focal spot and the detector allows the voxel size and FOV to be flexibly adjusted (Fig. 1c). Figure 1b–e shows XNH imaging and the resulting 3D rendering of the central brain of an\nDense neuronal reconstruction through X-ray holographic nano-tomography"
    }, {
      "heading" : "Aaron T. Kuan 1,8, Jasper S. Phelps 1,2,8, Logan A. Thomas1, Tri M. Nguyen 1, Julie Han 1, Chiao-Lin Chen3, Anthony W. Azevedo 4, John C. Tuthill 4, Jan Funke 5, Peter Cloetens 6, Alexandra Pacureanu 1,6 ✉ and Wei-Chung Allen Lee 7 ✉",
      "text" : "Imaging neuronal networks provides a foundation for understanding the nervous system, but resolving dense nanometer-scale structures over large volumes remains challenging for light microscopy (LM) and electron microscopy (EM). Here we show that X-ray holographic nano-tomography (XNH) can image millimeter-scale volumes with sub-100-nm resolution, enabling reconstruction of dense wiring in Drosophila melanogaster and mouse nervous tissue. We performed correlative XNH and EM to reconstruct hundreds of cortical pyramidal cells and show that more superficial cells receive stronger synaptic inhibition on their apical dendrites. By combining multiple XNH scans, we imaged an adult Drosophila leg with sufficient resolution to comprehensively catalog mechanosensory neurons and trace individual motor axons from muscles to the central nervous system. To accelerate neuronal reconstructions, we trained a convolutional neural network to automatically segment neurons from XNH volumes. Thus, XNH bridges a key gap between LM and EM, providing a new avenue for neural circuit discovery.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE\nadult Drosophila (120-nm voxels), in which large individual neuronal processes can be resolved (Extended Data Fig. 1a, Supplementary Video 1 and Methods). Figure 1f shows a rendering of an XNH scan from mouse cortex (100-nm voxels), in which cell bodies and larger dendrites can be resolved across multiple cortical layers. Figure 1g shows a virtual slice from a higher-resolution mouse cortex scan (30-nm voxels; Supplementary Video 2). At this resolution, many ultrastructural features are resolved, including mitochondria, endoplasmic reticulum, dendrites and myelinated axons (Fig. 1g, insets and arrows). However, identification of these ultrastructural features depends, in part, on prior knowledge of their 3D structure— for example, the tubular shape of mitochondria and dendrites.\nTo quantify the spatial resolution of XNH image volumes, we used Fourier shell correlation (FSC)25 (Methods). We performed scans with voxel sizes between 30 and 120 nm and measured spatial resolutions between 87 and 222 nm (Fig. 1h, Extended Data Fig. 1b–d,h Supplementary Data Table 1 and Supplementary Videos 1–4). We verified these values using an independent edge fitting measurement (Extended Data Fig. 1e–g).\nTo verify that XNH images faithfully reproduce tissue ultrastructure, we collected thin sections of samples after XNH imaging and imaged the same regions at higher lateral resolution with EM (Fig. 1i). We found that most of the larger neurites (>200 nm in diameter) in the EM image could be accurately identified from XNH (Extended Data Fig. 1i,j). This confirms that XNH image volumes contain sufficient membrane contrast and spatial resolution to resolve and reconstruct dense populations of large-caliber neurons (generally long-distance connections) without specific labeling. However, thin processes (such as axon collaterals and distal dendritic branches) are currently difficult to resolve with XNH alone. Although the focus of this study was densely stained tissue (that is, label free), we also demonstrated that XNH imaging is compatible with specific labeling of genetically defined cell types (Extended Data Fig. 5a).\nCorrelative XNH and EM for connectomic analysis. Pyramidal cells constitute the majority of neurons in the cerebral cortex and are vital for cortical function, but mapping their synaptic inputs\n1 mm\nb\nTransmission electron microscopy\ni\n5 µmh\nSample\nVolume rendering\nec\nX-ray focus\nKB mirrors\nSample Detector\nf\ng\n220 µm\n24 0\nµm\nMouse cortex 100 nm voxels\nI\nII/III\nV\n*\nMouse cortex 30-nm voxels\nPhase map\n100 µm\n100 µm\n4.102.100.09 Rad\nda\n20 0\nµm\n20 m\nm\n2 µm\n10 0\nnm\n1 µm 1 nm\nEM*\nXNH\nLM µCT 10 n m 10 µ m\n2 m\nm\n20 µ\nm\nPixel size\nField of view\nX-ray holographic nano-tomography\n50 100 150 200 250 0\n50\n100\n150\n200\nR es\nol ut\nio n\n(n m\n)\nFly leg Fly CNS Mouse cortex\n30 60 90 120 Pixel size (nm)\nField of view (µm)\nz1\nz2\nFig. 1 | XNH technique and characterization. a, Schematic depicting pixel and FOV sizes for XNH imaging, along with comparisons to other modalities (assumes a 4-Mpixel detector). Note that EM imaging is generally performed on thin sections or surfaces, whereas XNH, LM and micro computed\ntomography can penetrate thicker tissue samples. b, A Drosophila brain (blue arrow) embedded in resin and mounted for XNH imaging. c, Imaging setup: the X-ray beam is focused to a spot using two Kirkpatrick–Baez (KB) mirrors and traverses the sample before hitting the detector. Holographic projections of the sample (a result of free-space propagation of the coherent X-ray beam) are recorded for each angle as the sample is rotated over 180° (Extended Data Fig. 1a and Methods). d, Phase map of the sample shown in Fig. 1b, calculated by computationally combining holograms recorded at four different distances from the beam focus and the detector. Computed pixel values indicate phase in radians. e, 3D rendering of XNH volume of the central fly brain (120-nm voxels). The tissue outline is shown in blue, whereas neurons are highlighted in orange. f, 3D rendering of an XNH volume of mouse posterior parietal cortex (PPC) (100-nm voxels). Boundaries between cortical layers are shown in red. g, Virtual slice through a higher-resolution XNH volume of mouse primary somatosensory cortex (30-nm voxels). Insets: detailed views showing ultrastructural features, including mitochondria (magenta arrowheads), endoplasmic reticulum (magenta arrows), nucleolus (magenta asterisk), large dendrites (cyan) and myelinated axons (red). Scale bar, 10 μm. Insets are 10 μm in width. h, Measured resolution (obtained using FSC; see Methods and Supplementary Table 1) for different XNH scans plotted as a function of voxel size and FOV. Data points and error bars show mean ± IQR of sub-volumes sampled from each XNH scan. Number of sub-volumes used for each scan is shown in Supplementary Data Table 1. i, Comparison of XNH (50-nm voxels) and TEM (12-nm pixels and 100-nm section thickness) images of the same sample, the prothoracic leg nerve of an adult Drosophila.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE\nis challenging because their dendrites extend several hundreds of micrometers. In particular, ADs ascend to layer I, where they integrate long-range excitatory and local inhibitory inputs26 (Fig. 2a), but it is not known in detail how AD connectivity differs across pyramidal cell types. A recent study using large-scale EM revealed that ADs from superficial (layers II and III) pyramidal cells receive proportionally more inhibition than deep-layer (layer V) cells27. However, this study relied on relatively small sample sizes (n ≈ 20 cells per sample) owing to the FOV limitations of EM. In this study, we combined large FOV XNH (100-nm voxels) with targeted serial section transmission electron microscopy (TEM)28 on the same sample to characterize hundreds of pyramidal cell ADs in the posterior parietal cortex (PPC), an association area known to be involved in perceptual decision-making29. We first acquired two partially overlapping XNH scans of mouse PPC that span layers I–V (~8 h of imaging time) and then acquired a synapse resolution EM dataset from the bottom of layer I that contains the initial bifurcations of pyramidal ADs (~150 h of imaging time) (Fig. 2a–d, Extended Data Fig. 2a,b and Methods). All 3,234 cells within the XNH volumes were identified as excitatory pyramidal cells, inhibitory interneurons or glia based on morphology and subcellular features30 (Extended Data Fig. 2c). We observed a particularly high density of neuronal somata (both excitatory and inhibitory) concentrated at the top of layer II (designated layer IIa here) (Fig. 2e), which is consistent with histological data (Extended Data Fig. 2d). We traced ADs in the XNH data from pyramidal cell bodies in layers II, III and V up to the layer I/II boundary and identified the same ADs in the aligned EM dataset (n = 261 cells; Extended Data Fig. 2e,f and Methods). We annotated all synaptic inputs onto the ADs within the EM volume (that is, the bottom of layer I, near the initial bifurcations), labeling each as excitatory (targeting dendritic spines) or inhibitory (targeting dendritic shafts or spine necks) (Fig. 2d)26. We found that layer IIa cells received more inhibitory synapses and fewer excitatory synapses near the initial bifurcations than did deeper-layer cells (Fig. 2f), consistent with previous EM analysis27. We hypothesized that the increased inhibitory synapse fraction onto ADs of layer IIa cells was due to the proximity of their somata to the initial AD bifurcations, because pyramidal cell bodies receive strong inhibitory input from basket cell interneurons, and proximal AD trunks generally have fewer spines26. To test this, we measured the relationship between inhibitory fraction and distance from the soma (Fig. 2g–i and Methods). We found that, over the first ~100 µm of path-length from the soma, the fraction of inhibitory input onto ADs dropped dramatically. Interestingly, this drop was steepest for layer IIa cells (Fig. 2i and Extended Data Fig. 2g,h), such that\nI\nII/III\nV\nLo ca\nl i nh\nib iti on Lo ng -ra ng e ex ci ta tio n XNH\nEM\na\nCell density (per mm3)\nSo m\na de\npt h\n(µ m\nb le\nlo w\nL 1)\nSo m\na de\npt h\n(µ m\nb le\nlo w\nL 1)\nI\nIIb\nIII\nV\nIIa\nSo m\na de\npt h\nI II/III\nInhibitory synapses Excitatory synapses\nDendrite fragment\nAD p\nat hl\nen gt\nh\nSoma\nPyramidal Interneuron\nGlia\nn = 3,234\nSy na\nps e\nde ns ity (p er µ m d en dr ite )\nAD path-length\nSynapse density (per µm dendrite) Inhibitory synapse fraction\nn = 261 n = 261\nIIb\nIII\nV\nIIa\nAD path-length\nIn hi\nbi to ry sy na ps e fra\nct io\nn\nIIb\nIII V\nIIa Excititory PSDs Inhibitory PSDs\nXNH\nElectron microscopy\nb\nc\nd\ne f g\nh i\nInhibitory\nExcitatory\n2 µm\n1 µm\n–50\n50\n100\n150\n200\n250\n300\n0 0 50 100 150 200 200 300 4000 100250\n1.00\n0.75\n0.50\n0.25\n0.00\n1\n2\n0 10,000\n0\n50\n100\n150\n200\n250\n300\n0 2 0 1\n0\n100 µm\n1 µm\nFig. 2 | Correlative XNH–eM analysis of the connectivity statistics of pyramidal apical dendrites in the posterior parietal cortex. a, Experimental approach: XNH imaging covers superficial and deep layers of the PPC with sufficient resolution to resolve cell bodies and ADs. Targeted 3D EM volume captures the layer I/II interface region, enabling analysis of synaptic inputs onto the ADs near their initial bifurcations. b, Virtual slice of XNH data (4-µm coronal section, maximum projection). Cell somata and ADs are visible. Example layer II/III (green) and V (magenta) pyramidal cells are highlighted.\nc, 3D EM reconstruction of an AD bifurcation. Postsynaptic densities (PSDs) of excitatory (targeting spines, blue) and inhibitory (targeting shafts or spine necks, red) synaptic inputs are shown. d, Example EM images of inhibitory (red) and excitatory (blue) synapses onto the AD. e, Density of cell somata as a function of soma depth (micrometers below the layer I/II interface), classified as excitatory pyramidal cells (blue), inhibitory interneurons (red) or glia (yellow) (Extended Data Fig. 2c). The top of layer II (~30 µm) contains a high density of both excitatory and inhibitory neurons. n = 3,234 neurons. f, Left: synapse density plotted as a function of soma depth (micrometers below the layer I/II boundary). Excitatory and inhibitory synapses densities are shown in blue and red, respectively. Right: inhibitory synapse fraction plotted as a function of soma depth. Small markers correspond to one neuron. Large markers and error bars indicate mean and 95% confidence interval for each layer calculated via bootstrap analysis. n = 39, 99, 75 and 38 neurons for layers IIa, IIb, III and V, respectively. g, Schematic of dendrite fragment connectivity analysis. ADs within the EM volume were divided into fragments 10 µm in length. For each fragment, the density of synapses was recorded along with the path-length distance from the soma (AD path-length). h, Synapse densities (excitatory in blue, inhibitory in red) plotted as a function of path-length to soma. Each marker corresponds to a 10-µm-long dendrite fragment. Lines and shaded areas indicate binned average (20-µm bins) and IQR. i, Inhibitory synapse fraction plotted as a function of path-length to soma. Each marker corresponds to one dendrite fragment, colored based on soma type. Lines and shaded areas indicate binned average and IQR (mean ± s.e.) for each soma type.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE\nthe transition from inhibition-dominated to excitation-dominated input was spatially compressed for layer IIa cells.\nThis multi-scale approach combining XNH and EM in the same tissue sample enabled us to identify three unique properties of layer IIa cells: higher soma density, inhibition-dominated synaptic balance near the initial bifurcations of the ADs and spatially compressed transitions from inhibition-dominated to excitation-dominated input on the AD tufts. These distinct structural properties likely underlie unique functional properties and suggest that association cortex has pyramidal cell specializations beyond the canonical layer structure. Future work will be needed to determine the computational role of these layer IIa cells and whether similar cells exist in other cortical areas.\nMillimeter-scale XNH imaging of a Drosophila leg at singleneuron resolution. The Drosophila leg and ventral nerve cord (VNC) are model systems for studying limb motor control31–33, but we currently lack a detailed map of the sensory and motor neurons that innervate the fly leg. Leveraging the capability of XNH to penetrate millimeter-scale samples without physical sectioning, we imaged an intact Drosophila front leg (coxa, trochanter, femur and first half of the tibia segments) and the region of the VNC that controls this leg’s movements (Fig. 3a–c, Extended Data Fig. 3a, Supplementary Data Table 2 and Supplementary Video 4). By stitching ten XNH scans together into a single 3D volume covering\nover 1.4 mm along the leg’s main axis (Fig. 3c and Extended Data Fig. 3b), we obtained a comprehensive, high-resolution view of the leg’s structure, revealing not only motor and sensory neurons but also muscle fibers and sensory organs.\nFirst, we comprehensively mapped the sensory organs and their associated sensory neurons in the leg (Supplementary Data Table 3). Our count of organs on the surface of the leg was quantitatively consistent with previous studies that employed scanning EM to visualize these structures34 (Extended Data Fig. 3c–f). In contrast, we identified more internal sensory structures (Extended Data Fig. 3g) than were previously detected with genetic driver lines35. Because XNH is equally capable of resolving surface and internal structures, we were able to complete an exhaustive list of the mechanosensory organs in the fly’s coxa, trochanter, femur and first half of the tibia (Supplementary Data Table 3).\nNext, we reconstructed axons of different classes of sensory neurons to map their projections into the VNC. In doing so, we found systematic variation in the axon diameter of different sensory neuron types, suggesting that some types of sensory signals (namely those from coxal hair plates and trochanteral campaniform sensilla) are conducted to the VNC faster36 or more reliably37 than others (Fig. 3c and Extended Data Fig. 3h–k). Our reconstructions revealed that, although most sensory axons enter the VNC through the main leg nerve, the three different coxal hair plates project their axons into the VNC through three different nerves (Fig. 3c, cyan,\n5 µm\n*Femur\n25 µm\nT1 of VNC\nTi bi\na\nFe m\nur\nCo xa\nTrochanter\nTrochanter-innervating\nCoxa-innervating\nTibia-innervating\nFemur-innervating\nLong tendon muscle fibers\nProximal/Distal\nHair plates on the coxa Long tendon muscle fibers (proximal) (2) Long tendon muscle fibers (distal) (4) Tibia extensor muscle fibers (36) Tibia flexor muscle fibers (26) Tibia reductor muscle fibers (29) Campaniform sensilla on the trochanter\nExt. data fig. 3d\nExt. data fig. 3c\nf\nExt. data fig. 3l\n100 µm\nd\nMotor neurons\nSensory neurons\nb c Coxa\nMuscle fibers\nMuscle fibers\nFat cells\nEx os\nke let\nond e\nf\n1 mm 25 µm 5 µm\ng\nTro cha\nnte r\nFem ur\nTibia\nh 100 µm\nT1\nT2\nT3\nLeg\nVNC\nSensory Motor Brain\na\nFig. 3 | Millimeter-scale imaging of a Drosophila leg at single-neuron resolution. a, Schematic of XNH imaging strategy. Ten partially overlapping XNH scans (Supplementary Data Table 2) were used to capture a front leg’s coxa, trochanter, femur and half of the tibia, plus the prothoracic neuromere\n(T1) of the VNC that controls this leg’s movements. The final leg segment, the tarsus, contains no muscles and was not imaged. b, Photograph of a leg sample after heavy metal staining, resin embedding and mounting for XNH imaging. c, Rendering of reconstructed leg segments, sensory neurons, motor neurons and muscle fibers. Individual neurons were reconstructed from their target structures in the leg (sensory receptors or muscle fibers) into the VNC. d–g, Cross-sections through the coxa and femur at locations indicated by dotted lines in c. Color code is the same as in c. d, The arrangement of neurons, muscle fibers and fat cells in the coxa. e, Detailed view of the nerve from d. f, The six long tendon muscle fibers in the femur are organized as a group of two and a group of four, which attach to the long tendon at different locations (see c). The asterisk indicates the femoral chordotonal organ, a proprioceptive sensory structure (Extended Data Fig. 3g)31. g, Detailed view of the nerve from f. Arrowheads indicate swellings of motor neuron axons, likely sites of neuromuscular junctions. Visible here are two swellings from the only motor neuron that innervates these two fibers (light green; see c). A different motor neuron (dark green; see c) branches off of the leg nerve, traveling past the proximal fibers to innervate the distal fibers. h, Muscle fibers of the femur. The 97 fibers identified in the femur using XNH are nearly triple of that reported previously using fluorescence microscopy38.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE\nand Extended Data Fig. 3c,e). These results reveal a topographic organization for how these differently positioned (and, therefore, differently tuned) mechanoreceptors project their signals into the central nervous system.\nWe then turned to motor structures, reconstructing muscle fibers, tendons and motor neurons. Motor neurons and muscle fibers had large diameters (1–2 µm and 8–16 µm, respectively), enabling straightforward reconstruction throughout the dataset (Fig. 3c–h and Extended Data Fig. 3l). We identified 97 muscle fibers in the femur (Fig. 3h), significantly exceeding the 33–40 fibers reported previously using fluorescence microscopy38. Because XNH imaging also resolves the tendons that connect the muscle fibers to the exoskeleton, we were able to unambiguously define muscle groups by identifying muscle fibers that attach to the same tendon (Fig. 3c,h). For example, we found that six muscle fibers in the femur attach to the long tendon, rather than three as previously reported38. Two of the six (light red fibers) attach at the proximal tip of the long tendon and are innervated by a single motor neuron (Fig. 3c,g, light green), whereas the other four (dark red fibers) attach more distally and are innervated by two different motor neurons (one shown in Fig. 3c,g, dark green). This demonstrates that these two muscle fiber groups are under distinct neural control despite connecting to the same tendon. By comparing our reconstructions of motor neuron axons to single-neuron LM images, we were able to identify individual neurons in this dataset that have previously been studied in functional39 or developmental contexts40 (Extended Data Fig. 3m,n). These results highlight how a set of overlapping XNH scans can reveal the precise structural relationships between\nneurons, sensory receptors and muscle fibers crucial for adaptive control of limb movements.\nAutomated segmentation of neuronal morphologies using CNNs. Although XNH imaging of millimeter-sized circuits can be accomplished in time scales of hours, manual tracing of neurons can take months. To address this bottleneck, we applied machine learning algorithms to accelerate neuron reconstruction from XNH image data. We adapted an EM segmentation pipeline41 and applied it to an XNH image volume of a fly VNC encompassing most of a T1 neuromere and part of the front leg nerve (Fig. 4a, Extended Data Fig. 4a, Supplementary Video 2 and Methods). This pipeline uses a 3D U-NET CNN (Extended Data Fig. 4b) to make membrane predictions (in the form of an affinity graph; Fig. 4b,c) from XNH image data. Subsequently, voxels are agglomerated into distinct neuron objects based on the predicted affinities (Fig. 4d,e). The resulting neuronal reconstructions (Fig. 4f) contain 3D geometrical information, such as axon and dendrite caliber, that is usually absent from manual tracing.\nAccessing large populations of neuronal morphologies by segmentation of XNH data can reveal how circuits are organized. Leveraging this automated segmentation pipeline, we reconstructed 100 neurons that enter the VNC via the main leg nerve and identified them as motor or sensory neuron subtypes based on their axon caliber and main branching patterns31,40,42,43 (Fig. 4e–g, Supplementary Video 5 and Methods). We observed that axons are spatially organized in the nerve, such that neurons of the same morphological subtype tend to also have their axons physically\nb Raw XNH image Affinity prediction Segmentationc d\nfe Motor neurons\nCampaniform sensillum neurons\nHair plate neurons\nChordotonal organ neurons\nBristle neurons\n50 µm\n10 µm\ne\n20 µm\nf\nM id\nlin e\nLeg nerve\nRight T1\nleft T1\nV\nD\nLR\na\ng\nExample neurons by type\nFig. 4 | Automated segmentation of neuronal morphologies using CNNs. a, b, Raw XNH image data, recorded from the T1 neuromeres of an adult Drosophila VNC. V, ventral; D, dorsal; R, right; L, left. c, Predicted affinities output by a 3D U-NET (Extended Data Fig. 4b) corresponding to the region shown in b. The affinities quantify how likely it is that each voxel is part of the same neuron as neighboring voxels in z, y and x directions (plotted as RGB). In isotropic XNH data, affinities in different cardinal directions are usually similar, leading to images that appear mostly grayscale. The dark (low-affinity) voxels are the basis for membrane predictions. d, Segmentation corresponding to data shown in b and affinities shown in c. Each neuron is agglomerated\ninto a 3D morphology based on the affinities. In this visualization, each neuron has a unique color. e, Cross-section of the main leg nerve, showing motor and sensory axons reconstructed via automated segmentation. Coloring corresponds to neuron type, revealing spatial organization of neurons within the nerve. f, 3D visualization of 100 automatically segmented neurons in the Drosophila VNC. Coloring corresponds to neuron types determined based on 3D morphology. The dotted circle indicates the boundary of the T1 neuropil associated with control of the front leg. g, Example morphologies of VNC neuron subclasses (only four example neurons per type shown for clarity).\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE clustered within the nerve (Fig. 4e,f). Furthermore, these reconstructions constitute a database of neuron morphologies that can be corresponded with LM and EM data. For example, by examining the main branching patterns of the largest-diameter motor neuron, we were able to identify it as a fast tibia flexor motor neuron39 that is known to receive direct synaptic input from campaniform sensillum neurons28 (Extended Data Fig. 4c).\nTo quantify segmentation accuracy, we compared the segmentation to manual tracing of selected neurons, counting the number of split errors (in which different pieces of a neuron are erroneously labeled as separate neurons) and merge errors (in which two different neurons are erroneously joined) (Extended Data Fig. 4d,e). Tuning the segmentation parameters to minimize merge errors while still maintaining an acceptable number of split errors resulted in ~0.75 mergers and ~13 splits per neuron (Extended Data Fig. 4f and Methods). Generally, split errors were found in the most distal branches where the processes became thin, whereas the main branches were segmented with lower error rates. Nevertheless, we found that fixing segmentation errors via proofreading (merging ~13 fragments) was much faster than reconstruction via tracing (placing ~500 nodes).\nThese results suggest that automated segmentation of XNH data can be used to rapidly reconstruct morphologies for dense populations of neurons. Segmentation networks can also be transferred to different types of tissue. By adding a small amount of cortex-specific training data, we adapted the network to segment XNH data from mouse cortex (Extended Data Fig. 4g–k). Continued progress in neuron segmentation from EM data will likely also benefit segmentation of XNH data, and new approaches for automatic transfer learning might make it possible to generalize EM segmentation algorithms to XNH without needing substantial new training data44."
    }, {
      "heading" : "Discussion",
      "text" : "Applications of XNH to neural circuits. We demonstrate that XNH enables imaging of neural tissue with sufficient resolution and FOV to densely reconstruct individual neurons across millimeter-sized volumes. The resolutions achieved here enable reconstruction of the main dendritic and axonal branches of neurons, but smaller branches are not yet resolved. That said, these resolutions are sufficient for many applications, because a neuron’s main branches often clearly indicate its cell type45. In this fashion, we were able to identify pyramidal neuron cell types in mouse cortex (Fig. 2) and to differentiate sensory and motor neurons in the fly VNC (Figs. 3 and 4).\nGiven these results, XNH is poised to help address several fundamental questions in neuroscience. For instance, what are all the cellular components in a neuronal circuit, and how are those components arranged? Because heavy metals stain all cells, XNH represents an unbiased approach to mapping neural circuits that can reveal cell types that have previously gone undetected. Because genetic expression is not required, XNH can map millimeter-sized neural circuits in any animal, enabling comparative studies of neural circuit structure across species. With high imaging throughput, multiple samples can be imaged to reveal differences among individuals, developmental stages or disease models. With the large FOV, projectomes (that is, atlases of all large-caliber axonal projections between brain regions) can be rapidly mapped to provide a detailed framework for how information flows between brain regions. Projectomes have previously been painstakingly assembled using large-scale EM or built up from sparse fluorescent labeling46,47, but now the entire brain of smaller model organisms can be mapped in a typical beamline experiment (1–2 weeks) with XNH. Finally, compatibility with EM enables local synaptic connectivity to be studied in the same sample after XNH. This combined approach allows relatively small EM volumes to reveal new patterns of synaptic connectivity for different cell types.\nApproaches for volumetric imaging. The penetration power and sub-nanometer wavelength of high-energy X-rays makes them an ideal illumination probe for imaging thick (millimeter-scale), metal-stained tissue samples with nanometer resolution. For neural tissue, phase-contrast imaging at X-ray energies above 17 keV provides over 1,000-fold increase in contrast over attenuation contrast48. The technique we used in this study, XNH, combines the advantages of phase contrast with today’s smallest and brightest high-energy X-ray focus23 to reach resolutions needed for resolving individual neurons.\nXNH imaging is much faster than volumetric EM, in part because EM is typically performed at ~100× smaller voxel size. In principle, low-resolution serial blockface EM (with voxel sizes similar to XNH) can achieve imaging rates only ~2–3 times slower than XNH27,49. However, EM imaging of large samples is fundamentally limited by the need for physical sectioning, requiring either destructive sectioning (serial blockface EM) or painstaking collection of thousands of thin sections (serial section EM). With destructive sectioning, it is not feasible to survey large volumes quickly at lower resolution, followed by high-resolution imaging of sub-regions of interest, but this is possible with a combined XNH–EM approach (Fig. 2). Furthermore, not all samples can be reliably thin-sectioned—for example, the fly leg (Fig. 3) sections poorly owing to the material properties of the exoskeleton. Thus, XNH offers unique capabilities for non-destructive mapping of large circuits in both the central and peripheral nervous systems.\nBecause XNH is a wide-field imaging technique, teravoxel-sized datasets can be rapidly acquired within days of imaging, enabling a range of applications requiring high-resolution imaging of large FOVs. This aspect sets XNH apart from X-ray ptychography, another phase-contrast technique capable of high-resolution imaging of biological tissues13,50. Ptychography is a scanning technique; thus, data collection is slower. Furthermore, samples typically need to be smaller than ~100 µm in thickness for ptychography.\nIn all wide-field imaging modalities, the ratio of FOV to voxel size is determined by the size of the detector (effectively 2,048 × 2,048 for this work), but this ratio can be increased by using larger detectors or detector arrays. XNH offers additional flexibility because samples can be larger than the FOV of a single scan, and multiple sub-volumes can be imaged and stitched together to extend tissue coverage at high resolution. This allows users to select the optimal voxel size to ensure sufficient resolution for neuron reconstruction while maximizing imaging throughput.\nOutlook. Although XNH imaging can be implemented using a commercial X-ray source19, synchrotron sources are more suitable for obtaining high-quality data. Access to these facilities is usually granted via research proposals and, thus, is free for academic researchers. There are more than 50 synchrotron sources worldwide, and an increasing number of these are developing coherent imaging beamlines that could support XNH imaging.\nIt is worth noting that the resolutions achieved here (87–222 nm) are still far from the theoretical limits for hard X-rays, which have sub-nanometer wavelengths. In practice, XNH resolution is limited by focusing optics, mechanical stability and precision of stage movements, sample warping and performance of reconstruction algorithms, rather than by fundamental physical limits. Similarly, we expect continued improvements in imaging speed. Data collection can be accelerated by using faster and larger detectors, faster actuators and increased coherent photon flux. The upgrade of the ESRF source, completed in August 2020, along with planned improvements to X-ray optics and detectors, might enable faster imaging with the ability to resolve the thinnest neuron branches and the synapses between them, opening an array of applications in mapping neuronal circuit connectivity.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE Accession codes. Raw XNH data are available in publicly accessible repositories under the following accession codes:\n1. BossDB (https://bossdb.org/) https://bossdb.org/project/kuan_phelps2020 2. WebKnossos (https://webknossos.org/) https://wklink.org/8122 (XNH_ESRF_mouseCortex_30nm) https://wklink.org/7283 (XNH_ESRF_mouseCortex_40nm) https://wklink.org/9034 (XNH_ESRF_drosophilaBrain_120nm) https://wklink.org/6724 (XNH_ESRF_drosophilaVNC_50nm) https://wklink.org/8452 (XNH_ESRF_drosophilaLeg_75nm) 3. ESRF (https://data.esrf.fr/public/10.15151/ESRF-DC-21772\n8238) (anonymous login) DOI: https://doi.esrf.fr/10.15151/ESRF-DC-217728238\nonline content Any methods, additional references, Nature Research reporting summaries, source data, extended data, supplementary information, acknowledgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/ s41593-020-0704-9.\nReceived: 9 April 2020; Accepted: 5 August 2020; Published: xx xx xxxx"
    }, {
      "heading" : "Methods",
      "text" : "Experimental animals. Experimental procedures were approved by the Harvard Medical School Institutional Animal Care and Use Committee and performed in accordance with the Guide for Animal Care and Use of Laboratory Animals and the animal welfare guidelines of the National Institutes of Health. Mice (Mus musculus) used in this study were C57BL/6J-Tg(Thy1-GCaMP6s)GP4.3Dkim/J, male, 32 weeks old, and C57BL/6, male, 28 weeks old, ordered through Jackson Laboratory. Mice were housed up to four per home cage at normal temperature and humidity on reverse light cycle and relocated to clean cages every 2 weeks.\nFlies (Drosophila melanogaster) used in this study were 1–7-day-old female adults with the w1118 genetic background. The transgenic approach for labeling GABAergic nuclei (used in Fig. 3 and Extended Data Fig. 5) is described below.\nSee Life Sciences Reporting Summary for more details.\nSample preparation. Tissue samples were prepared for XNH imaging using protocols for EM, including fixation, heavy metal staining, dehydration and resin embedding4,51. For heavy metal staining, we used an enhanced rOTO protocol51 for all mouse samples and some of the fly samples. For other fly samples, we modified the protocol to increase4 or decrease heavy metal staining, but these variations did not have a large effect on XNH image quality. After staining, samples were dehydrated in a graded ethanol series and embedded in either TAAB Epon 812 (Canemco) or LX112 (Ladd Research Industries) resin. Resin-embedded samples were polymerized at 60 °C for 2–4 d. Polymerized samples were trimmed down to a narrow (1–2-mm diameter) rod using either an ultramicrotome or a fine saw and then glued to an aluminum pin. To smooth rough surfaces on the samples, which introduce noise into the XNH images, mounted samples were covered in a small droplet of resin, and the droplet was polymerized at 60 °C for 2–4 d.\nFor labeling APEX2-expressing cells (see below), we performed 3,3′-diaminobenzidine (DAB) staining after fixation and before heavy metal staining. Briefly, the nervous system from an adult female was dissected, fixed (2% glutaraldehyde and 2% formaldehyde solution in 100 mM sodium cacodylate buffer with 0.04% CaCl2) at room temperature for 75 min and then moved to 4 °C for overnight fixation in the same solution. The next day, the sample was washed in cacodylate buffer and then 50 mM glycine in cacodylate buffer and then cacodylate buffer again. To stain APEX2-expressing cells, the sample was incubated with 0.03% DAB in cacodylate buffer for 30 min, and then H2O2 was added directly to the incubating samples to reach an H2O2 concentration of 0.003%52. The reaction was allowed to continue for 30 min, after which the sample was washed in cacodylate buffer and inspected for visible staining product. Clusters of small brown puncta corresponding to the labeled nuclei were faintly visible (Extended Data Fig. 1g, top panel). The DAB and H2O2 incubations were repeated once more to increase the staining intensity. The sample was subsequently stained with 3-amino-1,2,4-triazole-reduced osmium4 and uranyl acetate and then dehydrated and embedded in LX112 resin.\nWe found that heavy metal staining, typical for EM studies51, improves membrane contrast in XNH images. However, heavy metal staining also increases X-ray absorption, causing heating and warping of the sample, thereby degrading image resolution. To counteract sample warping, we imaged in cryogenic conditions and optimized X-ray dosage to maximize signal but avoided excessive heating53. Samples that had major alignment artifacts due to warping or damage during X-ray imaging were excluded from further analysis.\nWe determined that, with optimal imaging conditions, even unstained tissue can generate sufficient contrast to trace large neurons (Extended Data Fig. 1h and Supplementary Video 6). The unstained sample (Extended Data Fig. 5b and Supplementary Video 6) was fixed in Karnovsky’s fixative, dehydrated in ethanol, cleared with xylene and embedded in paraffin. The embedded sample was trimmed down to a narrow (1–2-mm diameter) rod using a scalpel and inserted into a hollow aluminum pin with a 0.8-mm inner diameter for imaging.\nGeneration of nuclear-APEX2 flies. Based on the similarity between XNH and EM images, we reasoned that genetic labeling strategies previously developed for EM, such as APEX2 (refs. 52,54), could be adapted for XNH. We developed a fly reporter line that targets the peroxidase APEX2 (ref. 54) to cell nuclei (Methods) and demonstrated that labeled neurons could be identified in XNH datasets (Extended Data Fig. 5a).\nTo target APEX2 to the nucleus, we fused a targeting sequence consisting of a methionine and 38 amino acids of the Stinger sequence (MSRHRRHRQRSRSRNRSRSRSSERKRRQRSRSRSSERRR) to APEX2. The targeting sequence was first cloned into the pENTR vector and subsequently cloned by recombination using the Gateway system into a destination vector (gift from Frederik Wirtz-Peitz) containing UAS-attR-sbAPEX2-3xMyc. The resulting UAS-NLS-APEX2-Myc construct was used to generate a transgenic line by direct injection using φC31 site-specific integration at the attP40 docking site on chromosome 2.\nTo test whether APEX2-labeled cells could be identified via XNH imaging, we labeled GABAergic nuclei with APEX2. Fly lines containing the transgenes Gad1-p65AD, UAS-CD8-GFP and elav-Gal4DBD, UAS-CD8-GFP (gifts from Haluk Lacin) were crossed with the nuclear-APEX2 fly described above to generate flies with genotype w; elav-Gal4DBD, UAS-CD8-GFP / UAS-NLS-APEX2-Myc;\nGad1-p65AD, UAS-CD8-GFP /+. The nervous system from a 5–6-day-old adult female fly was prepared for XNH imaging as described above.\nTo automatically detect APEX2-labeled cell nuclei in XNH images, a 3D random forest pixel classifier was created, trained and deployed using ilastik55. For training, a sparse set of pixel labels was interactively annotated for background pixels and labeled cell body pixels.\nSee Life Sciences Reporting Summary for more details.\nExperimental setup and data acquisition. XNH imaging was performed at beamline ID16A at the ESRF in Grenoble, France. The end station of the beamline is placed 185 m from the undulator source for improved coherence. The X-ray beam was focused using fixed-curvature, multilayer-coated Kirkpatrick–Baez mirrors into a spot measuring about 15 nm at X-ray energy of 33.6 keV23 and 30 nm at 17 keV. The photon flux was on the order of 1–4 × 1011 ph s−1.\nThe sample stage and X-ray focusing optics were placed in a vacuum chamber (pressure ~10−8 mbar), and a liquid nitrogen-based cryogenic system was integrated inside the stage, keeping the sample at 120 K during imaging. For cryogenic imaging, the samples were transferred into the vacuum chamber with a Leica cryo-shuttle. The samples were placed on a high-precision rotation stage56 downstream of the beam focus, and intensity projections (that is, holograms) were recorded using a FReLon 4,096 × 4,096 pixel charge-coupled device detector57 with 2× binning, lens coupled to a 23-μm-thick GGG:Eu scintillator.\nAfter traversing the sample, the beam was allowed to propagate and generate self-interference patterns (that is, holograms). The resulting intensity was recorded on the detector placed 1.2 m downstream of the sample. The divergent beam gives geometrical magnification M = (z1 + z2) / z1 with z1 = focus-to-sample distance and z2 = sample-to-detector distance. Therefore, the pixel size and the corresponding FOV are proportional to z1 when the detector position is fixed (Fig. 1b). For each scan, four tomographic series of projections (rotations of the sample over 180°) were recorded at different focus-to-sample distances. To eliminate ring artifacts in tomographic reconstructions, the samples were laterally displaced at each rotation angle by a randomly determined distance of up to 25 pixels using high-precision piezoelectric actuators24. For each tomographic scan of the mouse cortex, 1,800 projections were recorded with exposure times of 0.1 s at X-ray energy 17 keV and 0.35 s at 33.6 keV. For the Drosophila scans at 17 keV, 2,000 projections were collected with 0.2-s exposure times.\nImage reconstruction. The recorded holograms were initially pre-processed to compensate for distortions and noise specific to the optics and detector and normalized with the empty beam24. For each rotation angle, the four holograms corresponding to different propagation distances were aligned and brought to the same magnification. Normally, the holograms are cropped to the smallest FOV, corresponding to the targeted pixel size. To obtain an extended FOV, the information from the three larger FOVs at lower resolutions was integrated in the reconstruction as well.\nFrom these sets of aligned holograms, phase maps were obtained through an iterative algorithm21,58–60. The initial approximations of the amplitude and phase were obtained through a method based on ref. 61, adapted for multiple propagation distance holograms59. For regularization, we used the ratio between the refractive index decrement δ and the absorption index β corresponding to osmium (δ/β = 27 for X-ray energy 33.6 keV and δ/β = 9 for 17 keV). This regularization was used only to obtain the starting point of the iterative approach and only affects low spatial frequencies. At each iterative step, the amplitude term was kept constant, and the phase term was updated. Typically, ten iterations were sufficient for the phase term to converge. Computation time was approximately 15 min per phase map (single CPU node). Computation of the phase maps was done in parallel by treating the holograms for each rotation angle independently.\nLastly, a 3D image volume of the tissue was generated by combining the phase maps from all angles into a tomographic reconstruction using filtered back-projection62. Iterative computed tomography approaches and regularization were not used here. Because we acquire and combine four sets of angular projections at four different geometrical magnifications, we can use the lower resolution— larger FOV information to reconstruct extended FOV tomograms. In this case, the reconstructed volume is larger than the detector size (Supplementary Data Table 1); however, the image quality degrades gradually toward the edges of the extended field because less information is available (Extended Data Fig. 1d).\nResolution measurements. Although the voxel size is directly determined by the sample positioning, the effective resolution depends on multiple factors, including the focal point size and the coherence properties of the X-ray beam, mechanical stability, detector characteristics, sample composition and image reconstruction approach. To measure the effective resolution, we used FSC and edge fitting independently (see below) and found the results to be consistent.\nFSC. To perform FSC25, we split the data into two independently acquired image volumes (see below) and measured the normalized cross-correlation coefficient between the two volumes over corresponding shells (size 6) in Fourier space. The intersection between the FSC line and the 1/2-bit threshold63 was used to determine the resolution (Extended Data Fig. 1c).\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE The two image volumes were generated independently from half of the phase maps (even and odd phase projections were separated). FSC was applied by comparing chunks from the two image volumes at corresponding locations. The size of these chunks was varied to find a size at which the FSC metric was stable, which occurred at chunk sizes of ~2003 voxels or larger. Measurements on larger chunks (up to 1,0003 voxels) remained stable but took longer to compute. Computation was performed on evenly spaced chunks across the volume, excluding the regions containing only empty resin. Once the resolutions for all chunks were measured, the median and interquartile range (IQR) were calculated (Fig. 1h and Extended Data Fig. 1b).\nFor characterization of resolution within a single scan (Extended Data Fig. 1d), FSC was performed on image cubes containing 1003 voxels, and each cube was plotted separately.\nEdge fitting. For measuring resolution by edge fitting, line paths perpendicular to sharp edges in the image volumes were annotated manually using CATMAID (Extended Data Fig. 1e,f, left)45,64. The image intensity along these line paths was then calculated using the pyMaid Python API (https://github.com/schlegelp/ pyMaid). The points along the line paths were fit to the sigmoid function:\np3 þ p0 2 1� tanh x � p1 p2\nwhere x is the length along the line path, and p1–4 are free parameters determined by nonlinear regression (Extended Data Fig. 1e,f, middle).\nGiven a fit to an edge, the measured resolution is given by:\nres ¼ asech 2ffiffi 2\np p2j j  \nThe fits to each line path were inspected, and poor fits were refit with different initial parameters or removed. Edge fitting was used in the 30-nm mouse cortex dataset (Extended Data Fig. 1e) and the 50-nm Drosophila VNC dataset (Extended Data Fig. 1f). For each dataset, 30 measurements were taken (Extended Data Fig. 1e,f, right). For purposes of comparison, we also applied edge fitting measurements to EM images of thin sections of Drosophila VNC (Extended Data Fig. 1g; 4-nm pixels and 45-nm-thick section).\nVariability in measured resolution. In XNH data, resolution is generally better for scans with smaller voxel size (Fig. 1h). However, measured resolution was significantly larger than the voxel size, between 1.5 and 3.5 times the voxel size. In EM images of nervous tissue, the ratio of measured resolution to pixel size was similar (Extended Data Fig. 1g). As the voxel size is reduced, the resolution per voxel deteriorates (Extended Data Fig. 1b). This is due to a combination of factors, such as more challenging conditions for phase retrieval and tomographic reconstruction and higher risk of sample warping during the scan. The photon flux density increases with smaller voxel sizes, so limiting the radiation dose and imaging at cryogenic temperatures is more critical.\nSample-to-sample differences also affect the resolution. Sample density can affect beam absorption and heating, and the location of the FOV relative to the mounting pin can affect heat dissipation. For one sample (fly leg), we imaged the same FOV with different voxel sizes and found that the measured resolution improved monotonically with smaller voxel size (Extended Data Fig. 1h).\nWe found that the measured resolution was approximately uniform across the scan volumes (that is, the tomographic reconstruction did not introduce major anisotropy in the image quality) (Extended Data Fig. 1d). However, the resolution near the axis of rotation (the center of the cylinder) appeared slightly better. Also, areas in extended FOV (areas outside the detector size, beyond the red line in Extended Data Fig. 1d) exhibited slightly degraded resolution. There might also be variation in measured resolution intrinsic to the evaluation method. For example, regions of empty resin (devoid of structure) within a sample exhibited poor resolution when measured by FSC. These regions were excluded from FSC calculations (Fig. 1h, Extended Data Fig. 1b and Supplementary Data Table 1).\nPost hoc EM imaging. After completing XNH imaging, samples were re-embedded in a block of resin and trimmed for thin sectioning. Serial thin sections (45–100 nm) were cut using a 35° diamond knife (DiATOME) and collected onto LUXFilm-coated copper grids (Luxel Corporation). Sections were imaged on a JEOL 1200EX transmission electron microscope (80-kV accelerating potential and 1,500× magnification), and images were acquired with a 20 MPix camera system (AMT Corp) at 4–12-nm pixels.\nFor the fly VNC sample, several thin sections, including the main leg nerve, were collected and imaged with TEM (Fig. 1i). The XNH image volume was rotated to match the orientation of the TEM sections using Neuroglancer (https:// github.com/google/neuroglancer). The TEM image of the leg nerve was elastically aligned to a single matching image taken from the XNH dataset using AlignTK (https://mmbios.pitt.edu/aligntk-home). Neurons in corresponding images from XNH and EM were independently segmented using the manual annotation software ITK-SNAP65 (www.itksnap.org) (Fig. 1i and Extended Data Fig. 1i). The segmentation generated from the EM image was taken as ground truth, and\nthe accuracy of the XNH segmentation was calculated by comparing it to the EM segmentation. For each neuron, segmentation was considered correct if the number of overlapping pixels shared between the EM and XNH segmentation was greater than half of the number of pixels for the neuron in both XNH and EM segmentations (Extended Data Fig. 1i, right). The size of each neuron was approximated as the diameter of the largest circle centered at the neuron’s center of mass that could fit entirely within the neuron (Extended Data Fig. 1j). Note that this analysis used only two-dimensional image data; additional 3D information would likely improve performance.\nFor the PPC sample, a 3D EM dataset in the PPC (Fig. 2) was collected and imaged using the GridTape pipeline for automated serial section TEM66. To find the region of tissue imaged with XNH, 1-µm-thick histological sections were collected and compared with XNH virtual slices. Next, 250 thin sections (~45-nm thick) were collected onto GridTape for a total of 11-µm total thickness. For each section, a region of interest overlapping with the XNH imaged region was imaged using a customized JEOL 1200EX TEM outfitted with a reel-to-reel GridTape stage. Total EM imaging time was approximately 150 h. In the EM images, the tissue ultrastructure, including chemical synapses, remained well preserved after XNH imaging (Extended Data Fig. 2b, inset and arrows). The EM images also contained small cracks (orange arrows) and bubbles (inset and pink arrows), which might have resulted from XNH imaging. These minor artifacts did not affect our ability to analyze the data, but it is possible that they can be reduced or eliminated by modifying XNH imaging protocols. However, more correlative XNH–EM data are needed to understand the origin of microcracks and nanobubbles.\nThe EM images were stitched together and aligned into a continuous volume using the software AlignTK (https://mmbios.pitt.edu/software#aligntk). The XNH datasets were aligned to the EM volume via an affine transformation based on manually annotated correspondence points (annotated using BigWarp (https://imagej.net/BigWarp)). Data annotation (tracing of AD morphologies and annotation of synapses) was done with CATMAID45,64.\nImage volume stitching. For each pair of XNH scan volumes with overlapping FOVs, correspondence points identifying the same feature in each scan were annotated manually using the ImageJ plugin BigWarp67 (https://imagej.net/ BigWarp). Translation–rotation–scaling matrices were calculated based on least-squares fitting of these correspondence points (~10–20 pairs per image volume) using custom MATLAB code and then applied to each image volume using the ImageJ plugin BigStitcher68. To avoid blurring from misalignments in regions where two scans overlap, image volumes were combined without blending in overlapping regions (custom Python code).\nData analysis—PPC. Manual tracing of neurons was performed by a team of two annotators using CATMAID45,64. All cell somata within the XNH volume were identified manually and classified as non-neuronal, pyramidal neuron or inhibitory neuron (Fig. 2e and Extended Data Fig. 2c)30,69,70. For a subset of pyramidal neurons distributed across layers II, III and V, the ADs were traced in the XNH volume up toward the superficial layers until they intersected the EM volume (Fig. 2b and Extended Data Fig. 2e). The same ADs were then identified in the EM volume based on their location and shape (Extended Data Fig. 2b). Within the EM volume, all incoming synapses to the AD were annotated as excitatory (targeting dendritic spines) or inhibitory (targeting dendritic shafts or spine necks) (Fig. 2d). Presynaptic axons, which were resolvable in the EM data but not the XNH data, were not traced. Pyramidal cells were classified as layer II, III or V based on the distance of their cell body from the layer I/II boundary, which was estimated as a plane above which the density of cell somata drops dramatically (Fig. 2b and Extended Data Fig. 2a). All tracing was reviewed independently by a second annotator to ensure accuracy.\nTo calculate synapse densities, we wrote custom Python code using the pyMaid Python API (https://github.com/schlegelp/pyMaid) to access the CATMAID database. To calculate synapse densities for a given AD (Fig. 2f), the total number of inhibitory or excitatory synapses found in the EM volume was divided by the total path-length of the AD within the EM volume. For these analyses, the location of the excitatory synapses was defined as the location of the base of the spine neck, and only the dendrite trunk (excluding the spines) was used for calculating the dendrite path-length. The inhibitory synapse fraction was defined as (number of inhibitory synapses / total number of synapses). To calculate synapse densities as a function of AD path-length (Fig. 2h–i and Extended Data Fig. 2g,h), each AD was split into fragments 10 µm in length, and the synapse densities were calculated for each fragment individually. The AD path-length was defined as the along-the-arbor distance from the center of the dendrite fragment to the soma (Fig. 2h–i) or initial bifurcation (Extended Data Fig. 2g,h).\nData analysis—Drosophila leg and VNC. Sensory receptors, muscle fibers and neurons were annotated manually using CATMAID45,64. Sensory receptors and muscle fibers were large enough to be clearly resolved in the XNH volume (50–75-nm voxels). Larger axons were also clearly resolved throughout the leg and VNC (motor neurons, coxal hair plate neurons and trochanteral campaniform sensilla neurons), but other smaller axons (bristle neurons in particular) were too small to be accurately traced. 3D visualizations were produced using ITK-SNAP\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE (Fig. 2c), the 3D viewer widget in CATMAID (Fig. 3, Extended Data Fig. 2e, Extended Data Fig. 3e–g,m,n and Extended Data Fig. 4d), Neuroglancer (Fig. 4 and Extended Data Fig. 4j,k), Paraview (Fig. 1e and Extended Data Fig. 3a) or Fiji (Fig. 1f and Extended Data Fig. 3c).\nAutomated segmentation. We used an automated segmentation workflow based on a segmentation pipeline for TEM data41. The pipeline consists of two major steps: affinity prediction and agglomeration. In the affinity prediction step, a 3D U-Net CNN was used to predict an affinity graph from the image data. The value of the affinity graph at any given voxel represents a pseudo-probability that adjacent voxels (in the x, y and z axes) are part of the same object. Adjacent voxels crossing object boundaries should have low affinity values, whereas voxels within neurons should have high affinity to the voxels surrounding them (including voxels contained in organelles or other subcellular structures).\nNetwork training. To expedite training a CNN on XNH data, we leveraged a CNN first trained on ground truth EM volumes from the CREMI challenge (https://cremi.org/), followed by training augmentation with corrected segmentation predicted on XNH data. We began by training an initial network on the CREMI ground truth data (4 nm × 4 nm × 40 nm) downsampled to match the voxel size of the XNH data (50 nm × 50 nm × 50 nm). We deployed this CREMI-trained network on a training volume of XNH data (320 × 320 × 300 voxels) and used Armitage (Google internal development software) to correct the voxel-wise segmentation for a sparse set of neurons. The network was then deployed on two more training volumes (200 × 200 × 200 voxels, one in the main leg nerve and one in the T1 neuropil), which were densely traced (via skeletonization, not voxel-wise) by human annotators (using CATMAID). Skeleton tracing was used in lieu of voxel-wise error correction because it can be completed in much less time and is less likely to introduce human errors in the training volumes. The tracing in these training volumes was used to correct errors in the candidate segmentation, and the corrected training volumes were then used to train the network further, resulting in the final network. The final network was then deployed on the entire dataset. Deploying the network on a server that has 40 CPU cores and ten Nvidia GTX 2080 Ti graphics cards across the full dataset (1,792 × 3,584 × 3,200 voxels) took less than 10 min.\nNeuron reconstruction and proofreading. We developed a proofreading workflow based on Neuroglancer (https://github.com/google/neuroglancer) to rapidly reconstruct and error correct neurons from automated segmentation. Although split and merge errors exist in the automated segmentation, such errors are usually easy for humans to recognize in 3D visualizations of reconstructed neurons. Thus, proofreading automated segmentation results is much faster than manual tracing.\nFor reconstruction and proofreading, a blocked segmentation methodology (in which the volume was divided into independent blocks of 2563 voxels) was used. Neurons were seeded by selecting a neuron fragment (contained within a single block) in the main leg nerve and sequentially grown by adding neuron fragments in adjacent blocks. During each growth step, the 3D morphology of the neuron was visualized and checked for errors. When merge errors occur, the blocks containing the merge are ‘frozen’ to prevent growth from the merged segment. When a neuron branch stops growing (has no continuations), the proofreader inspects the end of the branch to check from missed continuations (split errors). In this way, both split and merge errors can be corrected. In the fly VNC XNH dataset, neurons took about 10–30 min each to reconstruct and proofread.\nNeuron classification. Neurons were classified as motor neurons or sensory neuron subtypes based on their location in the nerve and 3D morphology28,40,42,43. The reconstructed neurons are likely missing branches or continuations where they become too small to be resolved by XNH. However, in most cases, the large-scale branching patterns were sufficient to classify the neurons. We reconstructed 166 neurons from seeds within the main leg nerve, out of which 66 were not clearly classified into a subtype and were excluded from Fig. 4f and Extended Data Fig. 4c. These unclassified neurons tended to be small fragments that did not extend substantially into the VNC, typically because they became too small to be reliably segmented (see also Extended Data Fig. 1i, j).\nSegmentation error quantification. To assess the accuracy of automated segmentation, we manually traced 90 neurons from the XNH data (CATMAID) and compared them to the automated segmentation results. For each neuron, a list of all skeleton node (manually placed)–segmentation fragment ID (automatically generated) pairs was generated. In a perfect segmentation, all skeleton nodes for a given skeleton would correspond to the same segmentation ID. For each manually generated skeleton (neuron), a split error was counted for each extra segmentation ID associated with nodes in that skeleton. Split errors that did not change the topology of the neuron were not counted. For each segmentation ID, a merge error was counted for each segmentation fragment that was paired with skeleton nodes from multiple different neurons. To accurately count the number of such merge errors, the blocked segmentation was used (see ‘Neuron reconstruction and proofreading’ above). This way, if two neurons are merged in two different places, it will count as two merge errors. It is worth noting that, in this calculation, merge\nerrors are only counted between the subset of neurons for which we performed manual skeletonization. Therefore, if portions of nearby un-skeletonized neurons were merged into the segmentation of a skeletonized neuron, that error would not be detected here. Visual inspection of the segmentation results suggest that this type of error is not overly common, but, nevertheless, the counts of merge errors reported here are likely an underestimate of the true rate of merge errors. It is important to note that, in the neurons shown in Fig. 4f and Extended Data Fig. 4c, most split and merge errors were corrected via reconstruction and proofreading.\nStatistics and reproducibility. The quality of XNH reconstructions depended on imaging settings and sample characteristics and was generally reproducible for a given set of parameters. For example, eight XNH scans of the same fly leg sample were recorded with the same imaging parameters with similar results (Supplementary Data Table 2). The 11 datasets reported in Fig. 1h, Supplementary Data Table 1 and Supplementary Videos are a representative sample of XNH reconstruction quality over a range of imaging and sample parameters. Scans acquired during exploratory experiments that yielded poor-quality data were not included for data analysis.\nFor statistical analysis in Fig. 2, the number of annotated neurons (n = 261) was calculated to ensure that a large number of sample points (>30) exist in each of the four sublayers (IIa, IIb, III and V). No a priori statistical power calculations were performed to determine sample size, but our sample sizes are larger than those reported in previous publications (ref. 27). For bootstrap analysis of variance (Fig. 2f), 1,000 synthetic samples were generated from each layer (layer IIa, layer IIb, layer III and layer V) by randomly selecting data points with replacement until the number matched the original dataset size. Then, the mean synapse density or inhibitory synapse fraction was calculated for all 1,000 synthetic samples. The plotted 95% confidence intervals plotted in Fig. 2f are the 2.5th and 97.5th percentile values from this distribution of synthetic sample means. This bootstrap analysis is a non-parametric test and does not assume normality or equal variances.\nEM micrographs shown in Fig. 1i and Extended Data Fig. 1i are representative images. Ten similar thin sections were prepared and imaged with similar quality, although some sections showed physical damage sustained during the sectioning process. EM micrographs shown in Fig. 2d and Extended Data Fig. 2b are representative images. More than 2 million images with similar quality were recorded from this sample using automated EM, although some regions exhibited small cracks and bubbles, which might have been caused by prior XNH imaging.\nThis study involved detailed anatomical analysis of nervous tissue samples. In most analyses, we examined fundamental organizational principles of neuronal morphology and connectivity, rather than comparing experimental and control samples. Therefore, randomization was not necessary. Our data were not allocated into groups; thus, blinding was not applicable. Data collection and analysis were not performed blinded to the conditions of the experiments.\nSee Life Sciences Reporting Summary for more details.\nReporting Summary. Further information on research design is available in the Nature Research Reporting Summary linked to this article."
    }, {
      "heading" : "Data and materials availability",
      "text" : "Raw XNH image data from this study are available in the following publicly accessible repositories: 1. BossDB (https://bossdb.org/) https://bossdb.org/project/kuan_phelps2020 2. WebKnossos (https://webknossos.org/) https://wklink.org/8122 (XNH_ESRF_mouseCortex_30nm) https://wklink.org/7283 (XNH_ESRF_mouseCortex_40nm) https://wklink.org/9034 (XNH_ESRF_drosophilaBrain_120nm) https://wklink.org/6724 (XNH_ESRF_drosophilaVNC_50nm) https://wklink.org/8452 (XNH_ESRF_drosophilaLeg_75nm) 3. ESRF (https://data.esrf.fr/public/10.15151/ESRF-DC-217728238) (anonymous login) DOI: doi.esrf.fr/10.15151/ESRF-DC-217728238 Source data for Fig. 2e,f,h,i are provided with the paper. See https://lee.hms.harvard.edu/resources for access to skeleton reconstructions via CATMAID. Other datasets, as well as the fly reporter line for nuclear-targeted APEX2 expression, are available from the corresponding authors upon reasonable request. Please contact joitapac@esrf.eu or wei-chung_lee@hms.harvard.edu."
    }, {
      "heading" : "Software and code availability",
      "text" : "Code is available as described below or from the corresponding authors upon reasonable request. Please contact joitapac@esrf.eu or wei-chung_lee@hms. harvard.edu. Data collection X-ray holographic nano-tomography data were acquired using custom code based on TANGO (https://www.tango-controls.org/about-us/#mission) and SPEC (https://www.certif.com/content/spec/) software packages.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE"
    }, {
      "heading" : "Data pre-processing",
      "text" : "X-ray holographic nano-tomography data were reconstructed using custom code written in Octave (https://www.gnu.org/software/octave/) and the PyHST2 software package (https://software.pan-data.eu/software/74/pyhst2). Stitching of XNH image volumes was performed using ImageJ (https://imagej.net, v. 1.52p) with the BigWarp and BigStitcher plugins. Alignment of serial EM images was performed with AlignTK (https://mmbios.pitt.edu/software#aligntk, v. 1.0.2). XNH and EM data were aligned to each other using BigWarp (https://imagej.net/ BigWarp). Data analysis FSC analysis was performed using custom code (https://github.com/jcesardasilva/ toupy/tree/master/toupy/resolution). Manual data segmentation of XNH and EM images was performed using ITK-SNAP (www.itksnap.org, v. 3.6.0). Manual data annotation (tracing) was performed using CATMAID (https://catmaid. readthedocs.io, v. 2018.11.09-682-g811c25a) and queried using the pyMaid API (https://pymaid.readthedocs.io, https://github.com/schlegelp/pyMaid, v. 1.1.2). Neuron segmentation was performed using a custom CNN pipeline (see Methods). Ground truth training data were prepared using Armitage (Google internal development software) and CATMAID. Neurons were reconstructed from segmentation data using Neuroglancer (https://github.com/ google/neuroglancer, v. 1.1.5). Source data are provided with this paper."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors thank T. Pedersen for pre-processing and alignment of image data; R. Xu, T. Pedersen and L. DeCoursey for neuron tracing; J. Shin, W.-W. Lou, M. Liu, Y. Hu and R. Xu for manual annotation of ground truth segmentation for CNN training; J. da Silva for providing code and assistance for FSC measurements; N. Perrimon, M. Pecot and H. Lacin for providing fly lines; R. Fetter and A. Thompson for sample preparation advice; P. Li and V. Jain for access to and support with Armitage software; Y. Hu and M. Osman for contributing code for segmentation accuracy measurements; R. Wilson and H. Somhegyi for discussion and advice; C. Harvey, R. Born, J. Moffitt and R. Wilson for comments on the manuscript; and BossDB (W. Gray-Roncal, D. Xenes and B. Webster) and WebKnossos (N. Rzepka) for hosting image data on public repositories. The authors acknowledge ESRF for granting beamtime for the experiments: LS2705, LS2845, IHLS2928, IHLS3121, IHHC3498, IHMA7 and IHLS3004. This work was supported by the National Institutes of Health (R01NS108410) and awards from the Edward R. and Anne G. Lefler Center and the Goldenson Family to W.C.A.L. A.P. has received funding from the European Research Council under the European Union’s Horizon 2020 Research and Innovation Programme (grant no. 852455)."
    }, {
      "heading" : "Author contributions",
      "text" : "A.T.K., J.S.P., J.C.T., A.P. and W.C.A.L conceptualized the project and designed experiments. J.S.P. and A.T.K. prepared samples. C.-L.C. built transgenic fly lines. P.C. and A.P. designed and built instrumentation and image reconstruction methods. A.P. optimized X-ray imaging and contributed beamtime. A.P., J.S.P. and A.T.K. performed X-ray imaging. A.P., A.T.K., J.S.P. and P.C. performed phase retrieval, tomographic reconstruction and data processing. J.S.P. and A.T.K. performed electron microscopy. A.T.K., J.S.P. and J.H. performed and managed tracing and annotation. J.F., T.M.N., L.A.T., A.T.K. and J.H. adapted and performed automated segmentation and error analyses. A.W.A. and J.C.T. provided light microscopy data of fly neurons. A.T.K., J.S.P., A.P., L.A.T., A.W.A. and J.C.T. analyzed the data. A.T.K., J.S.P., A.P. and W.C.A.L. wrote the paper. All authors assisted in reviewing and revising the manuscript."
    }, {
      "heading" : "Competing interests",
      "text" : "W.C.A.L. declares the following competing interest: Harvard University filed a patent application regarding GridTape (WO2017184621A1) on behalf of the inventors, including W.C.A.L., and negotiated licensing agreements with interested partners. GridTape EM imaging was used for results in Fig. 2."
    }, {
      "heading" : "Additional information",
      "text" : "Extended data is available for this paper at https://doi.org/10.1038/s41593-020-0704-9.\nSupplementary information is available for this paper at https://doi.org/10.1038/ s41593-020-0704-9.\nCorrespondence and requests for materials should be addressed to A.P. or W.-C.A.L.\nReprints and permissions information is available at www.nature.com/reprints.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE\nExtended Data Fig. 1 | See next page for caption.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE Extended Data Fig. 1 | X-ray Holographic Nano-Tomography (XNH) Technique and Characterization. a, Overview of XNH imaging and preprocessing. Left: Holographic projections of the sample (a result of free-space propagation of the coherent X-ray beam) are recorded for each angle as the sample is rotated over 180°, then normalized with the incoming beam. Center left: Phase projections are calculated by computationally combining four normalized holograms recorded with the sample placed at different distances from the beam focus. Center right: Virtual slices through the 3D image volumes are calculated using tomographic reconstruction. Right: The resulting XNH image volume can be rendered in 3D and analyzed to reveal neuronal morphologies. b, Quantification of resolution of XNH scans measured using Fourier Shell Correlation (FSC), normalized by each scan’s pixel size. At larger pixel sizes, the resolution per pixel improves, though the resolution itself is worse (see Fig. 1h). Datapoints and error bars show mean ± IQR of subvolumes sampled from each XNH scan. Number of subvolumes used for each scan is shown in Supplementary Data Table 1. c, Representative FSC curve shown with the half-bit threshold. The intersection between the FSC curve and the threshold is the measured resolution. d, Quantification of resolution within the 30 nm mouse cortex scan. Each dot represents an FSC measurement of a 100 voxel3 cube. Blue line and shaded band represent binned averages and standard deviation, respectively. The x-axis is the radial position of the center of the cube (distance from the axis of rotation). The red dotted line indicates the boundary of the scan – data points to the right of the line are from extended field of view regions (Methods). e, f, Edge-fitting measurements of spatial resolution. Although FSC is commonly used to quantify resolution in many imaging modalities including X-ray imaging, its implementation is somewhat controversial63. To ensure that FSC measurements were accurate, we also used an independent measure of resolution based on fitting sharp edges in the images (see Methods), which produced values consistent with those measured via FSC. Left: Example features used for edge-fitting resolution measurement. For both (e) mouse cortex and (f) fly central nervous system, mitochondria were primarily selected because they have dark contrast and sharp boundaries. Center: Example line scan (image intensity values along the orange lines in the feature images). The measured resolution is parameterized from a best-fit to a sigmoid function (Methods). Right: Distribution of edge-fitting resolution measurements for many features distributed throughout the image volumes. n = 30 features measured as shown; boxes shows median and IQR and whiskers show range excluding outliers beyond 1.5 IQR from the median. The median resolution measured via FSC is shown for comparison. g, Comparison of edge-fitting resolution measurements for two XNH scans and high-resolution transmission EM images. EM data was acquired from a ~40 nm thick section of Drosophila VNC tissue, imaged with 4 nm pixels. Resolution is plotted in units of pixels. n = 30 features for each dataset; boxes shows median and IQR and whiskers show range excluding outliers beyond 1.5 IQR from the median. h, Comparison of XNH images acquired from the same FOV in the same sample (fly leg) at different voxel sizes. Within this range, the resolution improves monotonically, but not linearly, with voxel size. i, Comparison of XNH and EM segmentations. The XNH and EM images shown in Fig. 1i were independently segmented. Colored patches in the left two images represent different neurons in the segmentation. The EM segmentation was taken as ground truth, and the XNH segmentation for each neuron was evaluated. The right-most image shows correct and incorrectly segmented neurons. j, Quantification of XNH segmentation accuracy. The proportion of correctly segmentation neurons is plotted as a function of neuron size. Neurons larger then 200 nm diameter were segmented correctly more than 50% of the time. Note that this analysis used only 2D image data – additional 3D information would likely improve performance. In addition to the size of the neurons, the membrane contrast is also an important factor in accurately segmenting neurons in XNH. In a few cases, membranes between two axons were not clearly visible in XNH, causing them to be erroneously merged (i). Motor neurons in the leg nerve were also challenging to segment because they contain complex glial wrappings that are not always clearly resolved in XNH (i, right size of images).\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE\nExtended Data Fig. 2 | Correlative XNH - eM analysis of the connectivity statistics of pyramidal apical dendrites in the posterior parietal cortex (PPC). a, 3D rendering of two aligned and stitched XNH datasets in the mouse PPC. Cell somata are colored in green (based on voxel brightness). Magenta plane indicates location of serial EM dataset. b, Aligned XNH virtual slice (left) and EM image (right) of the same region of cortical tissue (horizontal section). After XNH imaging and thin sectioning, the ultrastructure of the tissue remains well preserved, allowing identification of synapses (inset right, arrows). The EM images also showed small cracks (orange arrows) and bubbles (inset, pink arrows), which may have been caused by XNH imaging. c, Examples of pyramidal neurons (top), inhibitory interneurons (middle) and glia (bottom) from the XNH data. Cells types were identified by classic ultrastructural features30,69,70. Pyramidal cells were identified by their prominent apical dendrites, while glia were identified from the relative lack of cytoplasm in the somata and the presence of multiple darkly stained chromatin bundles near the edges of the nuclei. Images are 40 ×40 µm virtual coronal slices (100 nm thick). d, Histological slice of Nissl stained coronal section including posterior parietal cortex from the Allen Brain Atlas (http://atlas.brain-map.org/). Higher density of cells is evident at the top of layer II (consistent with Fig. 2e). e, Rendering of cells included in connectivity analysis. Apical dendrites were traced in the XNH data (yellow) from somata (colored spheres) up to the layer I/II boundary where we collected an EM volume (cyan). Although the EM volume only contains short (< 50 µm) fragments of each AD, combining data across hundreds of neurons allowed us to map synaptic I/E balance over hundreds of micrometers of path length (Fig. 2h-i). f, Histogram of locations (cortical depth) of traced cells used for analysis of synaptic inputs onto apical dendrites. g, Synapse densities (excitatory in blue, inhibitory in red) plotted as a function of path-length to the initial bifurcation (as opposed to cell soma in Fig. 2i-j). Each marker corresponds to one dendrite fragment 10 µm long. Lines and shaded areas indicate binned average (20 µm bins) and interquartile range (mean ± SE). h, Inhibitory synapse fraction plotted as a function of path-length to the initial bifurcation. Each marker corresponds to one dendrite fragment colored based on the soma type. Lines and shaded areas indicate binned average and interquartile range (mean ± SE) for each soma type individually.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE\nExtended Data Fig. 3 | See next page for caption.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE Extended Data Fig. 3 | Millimeter-scale imaging of a Drosophila leg at single-neuron resolution. a, 3D rendering of the dataset after individual scans were stitched together to form a continuous volume. b, The image volume was computationally unfolded (ImageJ) to reveal the entire 1.4 mm length of the main leg nerve. c, Volume rendering of the three hair plates that sense the thorax-coxa joint. The clusters are positioned differently within the joint, implying that they are sensitive to different joint angle ranges. d, Cross-section through the group of eight campaniform sensilla on the trochanter, revealing the underlying sensory neurons and their axons (blue, see Fig. 3c). e-g, Locations of sensory receptors in the leg. See also Supplementary Data Table 3. (e) Anterior view of external sensory structures. TiCSv1 and TiCSv2 are on the reverse (ventral) side of the tibia. (f) Posterior view of the trochanter, where large number of external mechanosensory structures reside. (g) Partially-transparent view of the leg revealing internal sensory structures (see Supplementary Data Table 3). Coxal stretch receptor: a previous report identified stretch receptor neurons in each of the distal leg segments (femur, tibia, and tarsus) that sense joint angles and are required for proper walking coordination35. We identified a neuron in the coxa whose morphology is consistent with the other stretch receptors and was possibly missed previously due to incomplete fluorescent labeling. This demonstrates that each major joint in the fly leg, and not only the distal joints, are monitored by a single stretch receptor neuron. Coxal strand receptor: we identified a single strand receptor in the coxa, innervated by a single sensory axon for which no cell body was visible in the leg. Strand receptor neurons are unique sensory neurons that have a cell body in the VNC instead of the leg71, but this type of neuron has only been previously identified in locusts and other orthopteran insects72. In this reconstruction, the strand receptor neuron’s axon enters the VNC through the accessory nerve, but could not be reconstructed back to its cell body in the VNC. h-k, Axons of some sensory neurons were large enough to reconstruct at the 150–200 nm resolution achieved here. Sensory neurons innervating coxal hair plates (cyan) and some trochanteral campaniform sensilla (blue) had axons with large diameters, similar in size to motor neuron axons (yellow). In contrast, axons of all chordotonal and bristle neurons were narrower. (h) Cross-section through the main leg nerve at the location indicated in (b). Axons from different sensory clusters bundle together. Two TrCS8 neurons have unusually large diameters (1050 nm and 850 nm, white circles; see Fig. 3c for full reconstruction of these axons). The remaining TrCS neurons have axon diameters of 430 ± 140 nm. Motor neurons (yellow) have diameters of 1-2 µm. The unresolved axons (areas indicated by red arrows) are chordotonal neurons and bristle neurons. (i) Cross-section through the ventral prothoracic nerve at the location indicated in (e). Axons from CoHP8 sensory neurons (blue, axon diameters of 1030 ± 90 nm) travel in this nerve, which also contains seven motor neuron axons (yellow), five of which innervate muscles in the coxa (left, axon diameters of 1140 ± 130 nm), and two of which innervate muscles in the thorax (left, axon diameters of 1880 and 2150 nm). The unresolved axons (red arrows) are likely bristle neurons. (j) Cross-section through the prothoracic accessory nerve at the location indicated in (e). Axons from CoHP4 sensory neurons (cyan, axon diameters of 1140 ± 240 nm) travel in this nerve. Shown here is a cross-section through one of two major branches of the prothoracic accessory nerve. This branch also contains five motor neuron axons (yellow, axon diameters 1610 ± 240 nm). (k) Cross-section through the dorsal prothoracic nerve at the location indicated in (e). Axons from CoHP3 sensory neurons (cyan, axon diameters of 1380 ± 20 nm) enter the VNC through this nerve. Shown here is the branch of the dorsal prothoracic nerve containing only the CoHP3 axons. Panels (h-k) are slices through reconstructed XNH volumes with 75 nm pixel size, subsequently Gaussian blurred with an 0.3 pixel radius. Axon diameters are reported as mean ± SD. l, Cross-section through the tibia. The nerve is substantially smaller than in Fig. 3d-g as only a subset of leg neurons extend into the tibia. m, Top: Morphology of a single motor neuron axon (green dye fill) innervating muscle fibers (red phalloidin stain) in the femur (image from Azevedo et al.39). Each fly has a single motor neuron with this recognizable morphology39,40. Bottom: XNH reconstruction of a motor neuron axon having the same recognizable morphology as the neuron as shown in the top panel. Red cylinders represent individual muscle fibers. n, Left: Morphology of the motor neuron LinB-Tr2 (image from Baek & Mann 200940, Copyright 1999 Society for Neuroscience). This motor neuron is born from Lineage B, the second largest lineage of motor neurons. Right: XNH reconstruction of motor neuron axon having the same recognizable morphology as the neuron shown in the left panel. The thin terminal branches were not resolved in the XNH reconstruction. References: 71 – Bräunig, P. & Hustert, R. Proprioceptors with central cell bodies in insects. Nature 283, 768–770 (1980). 72 – Bräunig, P. Strand receptors with central cell bodies in the proximal leg joints of orthopterous insects. Cell Tissue Res. 222, 647–654 (1982).\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE\nExtended Data Fig. 4 | See next page for caption.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRT NaTurE NEuroScIENcE Extended Data Fig. 4 | Automated Segmentation of Neuronal Morphologies using Convolutional Neural Networks (CNNs). a, Overview of XNH image volume encompassing the anterior half of the VNC and the first segment of a front leg of an adult Drosophila (200 nm voxels). A smaller, higher resolution (50 nm voxels) volume centered on the prothoracic (T1) neuromere of the VNC and including the initial segment of the leg nerve was used for automatic segmentation. b, Schematic of U-NET CNN architecture used for automated segmentation (adapted from41). Each blue arrow represents two successive convolutions. c, Morphological comparison of the motor neuron with the largest-diameter branches out of all front leg motor neurons, reconstructed from three different flies using different modalities. Arrows indicate the largest-diameter branches, which match well across the three reconstructions. Left: Reconstruction using automated segmentation of XNH images. Gray segment indicates a merge error that was corrected during proofreading (Methods). Middle: Reconstruction from LM images of a dye-filled motor neuron labeled by 81A07-Gal4. This motor neuron controls the tibia flexor muscle and produces the largest amount of force of any fly leg motor neuron yet identified39. Adapted from Azevedo et al.39. Right: Skeleton reconstruction from EM images. Adapted from Maniates-Selvin et al.28. d, Population of 90 neurons used for evaluating segmentation error rates. Skeletons were categorized based on their morphologies (as in Fig. 4f)40,42,43. White circle indicates the boundary of the T1 neuropil. A, anterior; P, posterior. e, Examples of merge and split errors. True membrane locations are shown in black. Errors usually result from incorrect prediction of which voxels correspond to membranes. f, Average error rates of segmentation for the 90 neurons shown in (f). Automated segmentation is parametrized by an agglomeration threshold that amounts to a trade-off between split and merge errors. Data points indicate split and merge error rates for different agglomeration thresholds (Methods). The ideal segmentation minimizes the time needed to identify and fix split and merge errors during proofreading (red arrow). Merge error calculations based on comparisons to sparse manual tracing are likely an underestimate of the true number of merge errors. Note that the human-annotated, ground truth segmentation of XNH data excludes some areas where features are too small to resolve; thus these error metrics for XNH segmentation may not be directly comparable to what has been reported for EM. g-j, Automated segmentation of XNH data in mouse cortex (primary somatosensory, layer 5, 30 nm voxels). (g) Raw data (h) Affinities (zyx corresponding to RGB colors). i, selected segmentation labels corresponding to (e). (j) Selected 3D renderings of segmented neuron fragments. k, Large FOV segmentation of myelinated axons in the white matter below mouse parietal cortex. Segmentation of such myelinated axons can enable tracing of long-range inputs between brain areas at single-cell resolution.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\nTechnical RepoRTNaTurE NEuroScIENcE\nExtended Data Fig. 5 | Additional staining approaches for XNH imaging. a, Top: Photograph of fly brain with GABAergic nuclei labeled with APEX2 (arrows). Middle: XNH images (120 nm pixels, 15 µm thick minimum intensity projection) of the same fly brain after heavy metal staining, showing clusters of dark, APEX2 labeled GABAergic cell nuclei (arrows). Bottom: XNH virtual slice (120 nm thick) and output from an automated Random Forest image classifier trained to detect labeled cells (green). b, XNH data (105 nm voxels) of a Drosophila brain that did not undergo heavy metal staining. Even in unstained soft tissue, phase-contrast imaging provides enough signal that single neurons can still be resolved. FOV encompasses the optic lobe and half of the central brain. See Supplementary Video 6 and Methods.\nNATuRe NeuRoSCieNCe | www.nature.com/natureneuroscience\n1 nature research | reporting sum m ary A pril 2020 Corresponding author(s): Wei-Chung Lee and Alexandra Pacureanu Last updated by author(s): July 2, 2020 Repor�ng Summary Nature Research wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency in repor�ng. For further informa�on on Nature Research policies, see our Editorial Policies and the Editorial Policy Checklist. Sta�s�cs For all sta�s�cal analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods sec�on. n/a Confirmed The exact sample size (n) for each experimental group/condi�on, given as a discrete number and unit of measurement A statement on whether measurements were taken from dis�nct samples or whether the same sample was measured repeatedly The sta�s�cal test(s) used AND whether they are one- or two-sided Only common tests should be described solely by name; describe more complex techniques in the Methods section. A descrip�on of all covariates tested A descrip�on of any assump�ons or correc�ons, such as tests of normality and adjustment for mul�ple comparisons A full descrip�on of the sta�s�cal parameters including central tendency (e.g. means) or other basic es�mates (e.g. regression coefficient) AND varia�on (e.g. standard devia�on) or associated es�mates of uncertainty (e.g. confidence intervals) For null hypothesis tes�ng, the test sta�s�c (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted Give P values as exact values whenever suitable. For Bayesian analysis, informa�on on the choice of priors and Markov chain Monte Carlo se�ngs For hierarchical and complex designs, iden�fica�on of the appropriate level for tests and full repor�ng of outcomes Es�mates of effect sizes (e.g. Cohen's d, Pearson's r), indica�ng how they were calculated Our web collection on statistics for biologists contains articles on many of the points above. So�ware and code Policy informa�on about availability of computer code Data collec�on X-ray holographic nano-tomography data was acquired using custom code based on TANGO (h�ps://www.tango-controls.org/about-us/ #mission) and SPEC (h�ps://www.cer�f.com/content/spec/ ) so�ware packages. Data analysis X-ray holographic nano-tomography data was reconstructed using custom code wri�en in Octave (h�ps://www.gnu.org/so�ware/ octave/) and the PyHST2 so�ware package (h�ps://so�ware.pan-data.eu/so�ware/74/pyhst2). Fourier shell correla�on analysis was performed using custom code (h�ps://github.com/jcesardasilva/toupy/tree/master/toupy/ resolu�on). S�tching of XNH image volumes was performed using ImageJ (h�ps://imagej.net, ver. 1.52p) with the BigWarp and BigS�tcher plugins. Alignment of serial EM images was performed with AlignTK (h�ps://mmbios.pi�.edu/so�ware#aligntk, ver. 1.0.2). XNH and EM data were aligned to each other using BigWarp (h�ps://imagej.net/BigWarp). Manual data segmenta�on of XNH and EM images was performed using ITK-snap (www.itksnap.org, ver. 3.6.0) Manual data annota�on (tracing) was performed using CATMAID (h�ps://catmaid.readthedocs.io, ver. 2018.11.09-682-g811c25a) and queried using the pyMaid API (h�ps://pymaid.readthedocs.io, h�ps://github.com/schlegelp/pyMaid, ver. 1.1.2). Neuron segmenta�on was performed using a custom CNN pipeline (see Methods). Ground truth training data was prepared using Brainmaps (Google) and CATMAID. Neurons were reconstructed from segmenta�on data using Neuroglancer (h�ps://github.com/google/neuroglancer, ver. 1.1.5). For manuscripts u�lizing custom algorithms or so�ware that are central to the research but not yet described in published literature, so�ware must be made available to editors and reviewers. We strongly encourage code deposi�on in a community repository (e.g. GitHub). See the Nature Research guidelines for submi�ng code & so�ware for further informa�on.\n2 n atu re research | rep o rtin g su m m ary A p ril 2 0 2 0 Data Policy information about availability of data All manuscripts must include a data availability statement. This statement should provide the following information, where applicable: - Accession codes, unique identifiers, or web links for publicly available datasets - A list of figures that have associated raw data - A description of any restrictions on data availability Raw XNH image data from this study are available in the following publicly accessible repositories: 1. BossDB (https://bossdb.org/) https://bossdb.org/project/Kuan_Phelps2020 2. WebKnossos (https://webknossos.org/) wklink.org/8122 XNH_ESRF_mouseCortex_30nm wklink.org/7283 XNH_ESRF_mouseCortex_40nm wklink.org/9034 XNH_ESRF_drosophilaBrain_120nm wklink.org/6724 XNH_ESRF_drosophilaVNC_50nm wklink.org/8452 XNH_ESRF_drosophilaLeg_75nm 3. ESRF (https://data.esrf.fr/public/10.15151/ESRF-DC-217728238) (anonymous login) doi: doi.esrf.fr/10.15151/ESRF-DC-217728238 See https://lee.hms.harvard.edu/resources for access to skeleton reconstructions via CATMAID Source data for figures 2e,f,h,i are provided with the paper Field-specific reporting Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection. Life sciences Behavioural & social sciences Ecological, evolutionary & environmental sciences For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf Life sciences study design All studies must disclose on these points even when the disclosure is negative. Sample size Fig. 1: Number of samples to be imaged was determined based on available granted beamtime. Fig. 2: (f,g) Number of annotated neurons (n = 261) was calculated to ensure that a large number of sample points (> 30) exist in each of the 4 sublayers (IIa, IIb, III, V). No a priori statistical power calculations were performed to determine sample size but our sample sizes are larger than those reported in previous publications (ref. 27). Fig. 4: Number of reconstructed neurons (n = 100) included most of the large-diameter neurons present in the prothoracic leg nerve that were amenable to rapid proof-reading. This sample was used to qualitatively demonstrate the variety of neuronal morphologies and was not used for statistical tests. Data exclusions Samples that had major alignment artifacts due to warping or damage during X-ray imaging were excluded. Replication 11 samples were imaged (see Extended Data Table 1), including multiple samples of Drosophila brain and mouse cortex. Several of them were imaged multiple times (see Extended Data Table 2), although for different fields of view. Across these samples, were observed reproducible image quality. Due to limitations in synchrotron beamtime, we did not image the same field of view more than once with the same imaging parameters. Randomization This study involved detailed anatomical analysis of nervous tissue samples. In most analyses, fundamental organizational principles of neuronal morphology and connectivity were examined, rather than comparing experimental and control samples. Therefore, randomization was not necessary. Blinding Our data was not allocated into groups, thus blinding was not applicable. Reporting for specific materials, systems and methods We require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response.\n3 n atu re research | rep o rtin g su m m ary A p ril 2 0 2 0 Materials & experimental systems n/a Involved in the study Antibodies Eukaryotic cell lines Palaeontology and archaeology Animals and other organisms Human research participants Clinical data Dual use research of concern Methods n/a Involved in the study ChIP-seq Flow cytometry MRI-based neuroimaging Animals and other organisms Policy information about studies involving animals; ARRIVE guidelines recommended for reporting animal research Laboratory animals Mus musculus, C57BL/6J-Tg(Thy1-GCaMP6s)GP4.3Dkim/J, male, 32 weeks and C57BL/6, male, 28 weeks. Housed up to 4 per home cage at normal temperature and humidity on reverse light cycle. Drosophila melanogaster, w1118 background, female, 1-7 day old adults. Wild animals No wild animals were used in this study. Field-collected samples No field-collected samples were used in this study. Ethics oversight All experimental procedures were approved by the Harvard Medical School Institutional Animal Care and Use Committee and were performed in compliance with the Guide for Animal Care and Use of Laboratory Animals and the animal welfare guidelines of the National Institutes of Health. Note that full information on the approval of the study protocol must also be provided in the manuscript."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2020,
    "abstractText" : "1Department of Neurobiology, Harvard Medical School, Boston, MA, USA. 2Program in Neuroscience, Harvard University, Boston, MA, USA. 3Department of Genetics, Harvard Medical School, Boston, MA, USA. 4Department of Physiology and Biophysics, University of Washington, Seattle, WA, USA. 5HHMI Janelia Research Campus, Ashburn, VA, USA. 6ESRF, The European Synchrotron, Grenoble, France. 7F.M. Kirby Neurobiology Center, Boston Children’s Hospital, Harvard Medical School, Boston, MA, USA. 8These authors contributed equally: Aaron T. Kuan, Jasper S. Phelps. ✉e-mail: joitapac@esrf.eu; wei-chung_lee@hms.harvard.edu Mapping the structure of the nervous system provides a foundation for understanding its function. However, comprehensive mapping at the scale of neuronal circuits requires imaging with both high resolution and large fields of view (FOVs). EM has sufficient resolution, but obtaining three-dimensional (3D) EM volumes of even small neural circuits requires collecting millions of EM images across thousands of thin sections and, therefore, can be prohibitively costly in terms of time and resources1–4. Conventional LM is limited in spatial resolution due to the diffraction limit (~250 nm, although super-resolution5,6 and expansion microscopy7,8 techniques can exceed this) and, thus, requires sparse fluorescent labeling to resolve individual cells. Furthermore, visible light does not easily penetrate tissue, requiring physical sectioning or tissue clearing for thick samples (>1 mm). As a result, the comprehensive set of cells comprising most neural circuits remains unknown. Thus, an imaging modality capable of resolving densely packed neurons over millimeter-scale tissue volumes could enable more complete characterization and understanding of neural circuits. High-energy X-rays (>10 keV) have the potential to image thick specimens with high spatial resolution owing to their strong penetration power and sub-nanometer wavelength. Attenuation-based X-ray microscopy techniques offer volumetric imaging of millimeter-scale samples, but these techniques rely on sparse labeling owing to limited contrast9. Phase-contrast imaging techniques, such as X-ray interferometry10–12, X-ray ptychography13,14, single-distance free-space propagation imaging15,16 and X-ray holography17–21, have brought substantial improvements to image quality but have yet to achieve the combination of resolution, FOV and contrast required for reconstruction of densely stained neuronal morphologies. Thus, until now, tracing of individual neuron morphologies from X-ray image data has been possible only through sparse labeling9,16,22. Here we demonstrate X-ray imaging of densely stained neural tissue at resolutions down to 87 nm across millimeter-sized volumes, enabling reconstruction of the main branching patterns of neurons within the imaged volume. To achieve this, we employed X-ray holographic nano-tomography (XNH)23,24 and made improvements by customizing sample preparation, incorporating cryogenic imaging and optimizing phase retrieval approaches. We show that targeted EM can be used to measure synaptic connectivity of neurons previously reconstructed via XNH. We used this correlative approach in mouse cortex to quantify how the balance of inhibitory and excitatory inputs onto apical dendrites (ADs) varies by pyramidal cell type (that is, layer). XNH imaging also allows reconstruction of structures that are difficult to physically section, such as the adult Drosophila leg. We present an XNH dataset of an intact leg in which we reconstructed internal structures, such as muscle fibers and sensory receptors, and traced their associated motor and sensory neurons back to circuits in the fly’s central nervous system. Finally, we applied a convolutional neural network (CNN) to automatically reconstruct neurons from XNH data. These results establish XNH as a key technique for biological imaging, which bridges the gap between LM and EM (Fig. 1a) to enable dense reconstruction of neuronal morphologies on the scale of neuronal circuits.",
    "creator" : "Springer"
  }
}