{
  "name" : "dacemirror.sci-hub.se_journal-article_127c79c3cfb91e160645efb49e01b6b5_schmid2019.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "3Dscript: animating 3D/4D microscopy data using a natural-language-based syntax",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "correspondence\n3Dscript: animating 3D/4D microscopy data using a natural-language-based syntax To the Editor — State-of-the-art 3D-rendering software for microscopy data (Imaris, Bitplane; Arivis 4D Viewer, Arivis AG; Volocity, PerkinElmer; FluoRender1) assembles animations based on key frames: the user stores different scene transformations in several key frames along a timeline, and the rendering engine creates a smooth animation by interpolating between them. The number of required key frames, however, increases considerably as animations become more complex: a full rotation around a single axis with constant speed requires at least three key frames, and substantially more are required for compound motions such as a combined rotation around multiple axes (Fig. 1a, Supplementary Video 1) or nonlinear motions, which are essential for achieving smooth and pleasant transitions. The definition of key frames by the user then becomes tedious and irreproducible.\n3Dscript, an ImageJ/Fiji2,3 plugin, addresses the need for an intuitive way to assemble complex and high-quality animations. Here, animations are described by a list of instructions such as “From frame 0 to frame 180 rotate by 180 degrees horizontally ease-out” written in a syntax that is based on natural English language (Fig. 1b, Supplementary Notes). Each sentence starts with a frame interval that is followed by an action (e.g., “rotate,” “translate,” “zoom,” “change”) and the associated parameters. It ends optionally with an easing keyword (e.g., “linear,” “ease-in,” “ease-out,” “ease-in-out”) describing nonlinear motions often used in the animation of user interface elements in modern web design. 3Dscript provides instructions for spatially transforming an object in 3D; for animating 4D timelapse data (Supplementary Video 2); and for changing rendering properties such as contrast, channel weights, clipping and so on (Supplementary Videos 3 and 4).\nUnlike in key-frame-based animation, arbitrarily complex motions are intuitively implemented via the chaining of multiple instructions. Transformations, which are generally order dependent, are naturally applied in the order in which they appear in the text. Mixing of rotations and translations appropriately allows users, for example, to shift the center of rotation and generate planet-like motions, with an object rotating at the same time around both its own and an offset axis. Multiple instructions that apply in the same frame interval can be written concisely as enumerations (Fig. 1b). For the animation of motions that follow parametric paths such as Lissajous curves, user-defined ImageJ macros can replace any numeric parameter in 3Dscript, such as the number of degrees in a rotation (Supplementary Notes, Supplementary Videos 5 and 6). Macros are evaluated at runtime as functions of animation time. A dedicated editor based on Fiji’s script editor2 supports users in composing animations. During typing, written text is automatically completed (Supplementary\n<instruction>\n<interval>\n<action>\n<rotate>\n<translate>\n<zoom>\n<change>\n<transition>\n<value>\n::= <interval> <action> <transition>\n::= From frame <number> to frame <number> | At frame <number>\n::= (<rotate> | <translate> | <zoom> | <change>)\n::= rotate by <value> degrees( horizontally | vertically | around <tuple>)\n::= translate( horizontally by <value> | vertically by <value> | by <tuple>)\n::= zoom by a factor of <value>\n::= change( <property> | channel <number> <property> to <value>\n::= (linear | ease-in | ease-out | ease-in-out)\n::= <number> | <ImageJ macro>\nb c\n... <instruction> <instruction>\n<prefix>: - <remaining instruction> - <remaining instruction>\n<instruction> ...\n3D sc\nrip t p\nar si\nng a\nnd a\nni m\nat io\nn m\nod ul\ne\nMultiple instructions\nImageJ 3D Viewer, SciView, Scenery, etc.\n3D sc\nrip t\nin te\nrn al\nr en\nde re r B ig D at a V ie w er\nP O\nV -R\nay\nre nd\ner er\nSingle instruction\na 22 68 137 170\nFrom frame 0 to frame 600: - rotate by 720 degrees horizontally - rotate by 180 degrees vertically\nNature Methods | www.nature.com/naturemethods\ncorrespondence\nVideo 7). If a macro is used, the function skeleton is automatically created (Supplementary Video 6). Furthermore, the instructions for transitions between two user-defined rendering states can be inserted automatically (Supplementary Video 8). The editor handles exceptions such as syntax errors and can export ImageJ macros suitable for batch rendering.\nOur software includes a 3D raytracer (Supplementary Fig. 1) based on OpenCL (Khronos Group). Contrast and transparency are adjusted on the basis of minimum, maximum and gamma values defined separately for intensity and transparency, for each channel (Supplementary Fig. 2). Different rendering algorithms combine the opacity of multiple channels, render them independently or generate a maximum-intensity projection (Supplementary Fig. 3). With per-channel lighting (Supplementary Fig. 4), this allows for a very fine-grained adjustment of the visual outcome, beyond the possibilities offered by existing software. Datasets can be cropped from both directions along all three dimensions. Furthermore, front and back clipping planes can be defined to provide views inside a volume from oblique angles. All these settings can be animated with the proposed animation language.\n3Dscript is intended to be used in combination with the integrated 3D renderer. However, a clean separation of parsing and animation from rendering allows developers to easily replace the rendering engine with third-party software such as ClearVolume4, SciView (https://github.com/scenerygraphics/ SciView) or Scenery (https://github.com/ scenerygraphics/scenery), which can adjust the syntax of the language by extending it with custom keywords adapted to its capabilities (Fig. 1c, Supplementary Fig. 5).\nWe demonstrate this by providing implementations using the ImageJ 3D viewer5, the BigDataViewer6 and POV-Ray, a software for photorealistic rendering (Fig. 1c, Supplementary Videos 9 and 10, Supplementary Notes), as renderers.\nOverall, our text-based animation framework offers a substantial increase in comfort compared with traditional methods for composing high-quality 3D/4D animations. Its adaptation to existing scientific visualization software will truly raise the standard for the presentation of biomedical imaging data.\nreporting summary Further information on research design is available in the Nature Research Reporting Summary linked to this article."
    }, {
      "heading" : "Code availability",
      "text" : "The peer-reviewed version of the software is available as Supplementary Software. The source code is available at https:// github.com/bene51/3Dscript, and binary releases for Windows, Linux and Mac OS X versions are available from our Fiji update site, https://romulus.oice.uni-erlangen.de/ updatesite/. User documentation is available at https://bene51.github.io/3Dscript.\ndata availability All raw data used to create the figures and videos in this paper are available from the corresponding author upon reasonable request. ❐\nBenjamin Schmid 1,2*, Philipp Tripal1, Tina Fraaß1, Christina Kersten 3, Barbara Ruder3, Anika Grüneboom4, Jan Huisken 2,5,6 and Ralf Palmisano 1 1Optical Imaging Centre Erlangen, University of"
    }, {
      "heading" : "Erlangen-Nuremberg, Erlangen, Germany. 2Max Planck Institute of Molecular Cell Biology",
      "text" : "and Genetics, Dresden, Germany. 3Department of\nMedicine 1, University of Erlangen-Nuremberg,"
    }, {
      "heading" : "Erlangen, Germany. 4Department of Medicine",
      "text" : ""
    }, {
      "heading" : "3, University of Erlangen-Nuremberg, Erlangen,",
      "text" : "Germany. 5Morgridge Institute for Research,"
    }, {
      "heading" : "Madison, WI, USA. 6Department of Integrative Biology, University of Wisconsin, Madison, WI, USA. *e-mail: Benjamin.Schmid@fau.de",
      "text" : "Published: xx xx xxxx https://doi.org/10.1038/s41592-019-0359-1"
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank J. He and E. Haynes for the time-lapse image data of the zebrafish nervous system; A. Wandersee for the image data of the mouse organoid; D. Thieme for the image data of the human cornea; and A. Schmied and K. Enderle for extensive testing and feedback. This work was supported by DFG-CRC1181 Z02 (T.F.); DFG-CRC1181 C02 and DFG-FOR2438 P9 (C.K., A. Schmied and K. Enderle; awarded to C. Neufert, Med1, UK Erlangen); DFG-CRC1181 C05 and DFG-CRC796 B9 (A. Wandersee and B.R.; awarded to C. Becker, Med1, UK Erlangen); DFG-CRC1181 A02 (A.G.); and ERC-2014-CoG 647885 (SmartMic; J.H.)."
    }, {
      "heading" : "Author contributions",
      "text" : "B.S., R.P. and J.H. conceived the project. B.S. designed and implemented the software. C.K., B.R. and A.G. prepared samples and acquired imaging data. P.T. and T.F. tested the software on image data from multiple acquisition modalities. B.S., R.P. and J.H. wrote the manuscript. R.P. and J.H. supervised the project."
    }, {
      "heading" : "Competing interests",
      "text" : "The authors declare no competing interests."
    }, {
      "heading" : "Additional information",
      "text" : "Supplementary information is available for this paper at https://doi.org/10.1038/s41592-019-0359-1.\nNature Methods | www.nature.com/naturemethods\n1 nature research | reporting sum m ary O ctober 2018 Corresponding author(s): Benjamin Schmid Last updated by author(s): Feb 7, 2019 Reporting Summary Nature Research wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency in reporting. For further information on Nature Research policies, see Authors & Referees and the Editorial Policy Checklist. Statistics For all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section. n/a Confirmed The exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement A statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly The statistical test(s) used AND whether they are one- or two-sided Only common tests should be described solely by name; describe more complex techniques in the Methods section. A description of all covariates tested A description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons A full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) AND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals) For null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted Give P values as exact values whenever suitable. For Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings For hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes Estimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated Our web collection on statistics for biologists contains articles on many of the points above. Software and code Policy information about availability of computer code Data collection Data shown in this publication were acquired on a LaVision Biotec Ultramicroscope II, controlled by ImSpector (version 5.1.304), a Zeiss Spinning Disk Confocal Microscope controlled by ZEN blue (version 2.3.69.1017) and a Zeiss LSM 880 NLO Microscope controlled by ZEN black (version 2.1 SP3). Data analysis Fiji/ImageJ was used for data pre-processing. The published software was implemented as a plugin for Fiji. ffmpeg was used to encode the supplementary videos. For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors/reviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Research guidelines for submitting code & software for further information. Data Policy information about availability of data All manuscripts must include a data availability statement. This statement should provide the following information, where applicable: - Accession codes, unique identifiers, or web links for publicly available datasets - A list of figures that have associated raw data - A description of any restrictions on data availability All raw data used to provide the figures and movies of this study are available from the corresponding author upon request.\n2 nature research | reporting sum m ary O ctober 2018 Field-specific reporting Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection. Life sciences Behavioural & social sciences Ecological, evolutionary & environmental sciences For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf Life sciences study design All studies must disclose on these points even when the disclosure is negative. Sample size This publication introduces a new concept, together with an implementation in software, for animating 3D microscopy data. Therefore, a quantification of an experiment is not part of this study. However, we show the applicability of our software to four different sample datasets, which were acquired on three different microscopes. Data exclusions No data was excluded. Replication The results, in particular the figures and movies, can be reproduced following the steps described in the manuscript and the supplementary material. Randomization This publication introduces a new concept, together with an implementation in software, for animating 3D microscopy data. Therefore, a quantification of an experiment is not part of this study, and randomization is not relevant. Blinding This publication introduces a new concept, together with an implementation in software, for animating 3D microscopy data. Therefore, a quantification of an experiment is not part of this study, and blinding is not relevant. Reporting for specific materials, systems and methods We require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response. Materials & experimental systems n/a Involved in the study Antibodies Eukaryotic cell lines Palaeontology Animals and other organisms Human research participants Clinical data Methods n/a Involved in the study ChIP-seq Flow cytometry MRI-based neuroimaging"
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2019,
    "abstractText" : "To the Editor — State-of-the-art 3D-rendering software for microscopy data (Imaris, Bitplane; Arivis 4D Viewer, Arivis AG; Volocity, PerkinElmer; FluoRender1) assembles animations based on key frames: the user stores different scene transformations in several key frames along a timeline, and the rendering engine creates a smooth animation by interpolating between them. The number of required key frames, however, increases considerably as animations become more complex: a full rotation around a single axis with constant speed requires at least three key frames, and substantially more are required for compound motions such as a combined rotation around multiple axes (Fig. 1a, Supplementary Video 1) or nonlinear motions, which are essential for achieving smooth and pleasant transitions. The definition of key frames by the user then becomes tedious and irreproducible. 3Dscript, an ImageJ/Fiji2,3 plugin, addresses the need for an intuitive way to assemble complex and high-quality animations. Here, animations are described by a list of instructions such as “From frame 0 to frame 180 rotate by 180 degrees horizontally ease-out” written in a syntax that is based on natural English language (Fig. 1b, Supplementary Notes). Each sentence starts with a frame interval that is followed by an action (e.g., “rotate,” “translate,” “zoom,” “change”) and the associated parameters. It ends optionally with an easing keyword (e.g., “linear,” “ease-in,” “ease-out,” “ease-in-out”) describing nonlinear motions often used in the animation of user interface elements in modern web design. 3Dscript provides instructions for spatially transforming an object in 3D; for animating 4D timelapse data (Supplementary Video 2); and for changing rendering properties such as contrast, channel weights, clipping and so on (Supplementary Videos 3 and 4). Unlike in key-frame-based animation, arbitrarily complex motions are intuitively implemented via the chaining of multiple instructions. Transformations, which are generally order dependent, are naturally applied in the order in which they appear in the text. Mixing of rotations and translations appropriately allows users, for example, to shift the center of rotation and generate planet-like motions, with an object rotating at the same time around both its own and an offset axis. Multiple instructions that apply in the same frame interval can be written concisely as enumerations (Fig. 1b). For the animation of motions that follow parametric paths such as Lissajous curves, user-defined ImageJ macros can replace any numeric parameter in 3Dscript, such as the number of degrees in a rotation (Supplementary Notes, Supplementary Videos 5 and 6). Macros are evaluated at runtime as functions of animation time. A dedicated editor based on Fiji’s script editor2 supports users in composing animations. During typing, written text is automatically completed (Supplementary <instruction>",
    "creator" : "Springer"
  }
}