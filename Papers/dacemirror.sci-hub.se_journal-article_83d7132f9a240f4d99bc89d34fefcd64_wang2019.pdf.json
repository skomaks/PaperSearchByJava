{
  "name" : "dacemirror.sci-hub.se_journal-article_83d7132f9a240f4d99bc89d34fefcd64_wang2019.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Nanomaterials Discovery and Design through Machine Learning",
    "authors" : [ "Ming Wang", "Ting Wang", "Pingqiang Cai", "Xiaodong Chen" ],
    "emails" : [ "chenxd@ntu.edu.sg" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ESSAY\n1900025 (1 of 7) © 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim"
    }, {
      "heading" : "Nanomaterials Discovery and Design through",
      "text" : ""
    }, {
      "heading" : "Machine Learning",
      "text" : ""
    }, {
      "heading" : "Ming Wang, Ting Wang, Pingqiang Cai, and Xiaodong Chen*",
      "text" : "Dr. M. Wang, Dr. T. Wang, Dr. P. Cai, Prof. X. Chen Innovative Center for Flexible Devices (iFLEX) School of Materials Science and Engineering Nanyang Technological University 50 Nanyang Avenue, 639798, Singapore E-mail: chenxd@ntu.edu.sg\nThe ORCID identification number(s) for the author(s) of this article can be found under https://doi.org/10.1002/smtd.201900025.\nDOI: 10.1002/smtd.201900025\nand applications (Figure 1).[20–37] Although machine learning has shown the capabilities of making predictions with little human input, high time-efficiency and performance-efficiency, it also creates new challenges in guaranteeing the prediction accuracy for nanomaterials science.\nIn this essay, we focus on the new trends and features of machine learning in nanomaterials discovery and design, which could promote nanomaterials development. The challenges and perspectives of machine learning in predicting the discovery of new nanomaterials and the relationships between structure and property are identified and discussed. We hope this essay could give readers some inspiration for further research and applications of machine learning in nanomaterials."
    }, {
      "heading" : "2. General Process of Machine Learning in Nanomaterials Discovery and Design",
      "text" : "Machine learning is a broad class of algorithms and mathematical models, which renders computers the ability to automatically learn knowledge from existing empirical data (training data) and make prediction on a specific task. According to the learning style, machine learning algorithms can be classified into three classes: supervised, unsupervised, and semi-supervised learning.[38] In supervised learning, training data consisting of the labeled input–output pairs are used to train a model that can predict the correct output for a series of given unknown input. Supervised learning is the most widely used and powerful approach among these approaches in current studies, which includes various algorithms such as classification, regression, support vector machines (SVM), random forests, supervised artificial neural network (ANN). On the other hand, training data are unlabeled in unsupervised learning, which are used to identify trends, patterns, or clustering of the original data. In semi- supervised learning, only a limited amount of training data are labeled, which are associated with unlabeled data to serve trained model.\nThe general process of machine learning in nanomaterials science consists of two main steps: feature engineering from database to features and model building from features to models (Figure 2a). In feature engineering, some fixed-dimensional feature vectors (called descriptors or attributors) are firstly generated to represent the raw nanomaterials. The features in most research works are encoded in the available structure and property parameters, such as structure properties (dimension, roughness, crystal structure, etc.), mechanical properties (Young’s modulus, strength, hardness, etc.), electrical properties (resistivity, permittivity, dielectric strength, etc.), magnetic properties, thermal properties. Then these features are used as inputs to train a machine learning model, which is called model building. For applications, the tasks of machine learning are predicting the nanomaterials properties (macroscopic and\nNanomaterials Informatics"
    }, {
      "heading" : "1. Introduction",
      "text" : "Machine learning, a subfield of artificial intelligence (AI), has attracted increasing attention due to its high success in computer vision, speech recognition, and natural language processing.[1,2] In several domains that were previously thought to be mastered only by humans, for example, complex strategy games and medical-image diagnosis, machine learning-derived systems have shown human expert-level, sometimes even exceeding human expert capabilities.[3–5] This frontier is continuing to expand into many other fields, such as quantum physics, computational chemistry, and basic biomedical research.[6–9] Nanomaterials, possessing many unique physicochemical properties as compared with their bulk counterparts, have shown promising applications in energy conversion and storage, water remediation, medical treatment, data storage and information processing, etc.[10–15] Machine learning is also revolutionizing nanomaterials research and applications in recent years.\nIn previous nanomaterials science, experimental and computational simulating methodologies are two mainstream routes to explore nanomaterials, both of which require specialized domain knowledge.[16] They are inherently limited by experimental conditions (high equipment requirements, extreme experimental environment, limited practical experience, etc.) or existing theoretical foundations (sophisticated electron motion, molecular dynamics, microstructures, etc.). Especially with the increasing chemical complexity (Lipinski virtual chemical space reaching up to 1060), the prediction of new nanomaterials and properties is unreachable by using these two traditional approaches.[7,17] Hence, there is an urgent need to develop a new paradigm with both time- and performance-efficiency for nanomaterials science. With the launch of materials genome initiative (MGI) in 2011, Materials 4.0 is emerging.[18] More and more nanomaterial-related databases are available, such as Nanoparticle Information Library (NIL), Nano-HUB database, and Investigation Study Assay tab-delimited format (ISA-TABNano).[19] Moreover, with the improvement of computational capabilities and algorithms, machine learning is paving a promi sing path to accelerating nanomaterials discovery, design\nSmall Methods 2019, 1900025\nwww.small-methods.com\n© 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim1900025 (2 of 7)\nmicroscopic) and discovering new nanomaterials, which include the typical quantitative structure property relationship (QSPR), quantitative structure activity relationship (QSAR), composition and configuration of chemical space (Table 1).[20–37,39–53]\nIn the general process of machine learning, feature engineering is critical to guarantee the performance of models, because only the relevant features are meaningful for the construction of prediction models.[32,38] However, the selection of most appropriate features is quite challenging due to the requirements of deep insight into both domain-expert know ledge and the implementation of learning algorithms, which is a hot topic of current research. In model building step, typical supervised,\nSmall Methods 2019, 1900025\n© 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim1900025 (3 of 7)\nunsupervised, or semi-supervised learning algorithms are used to train a model for guiding nanomaterials design. During the training process, most of internal variables (hyperparameters) of models require being estimated in advance using systematic/ random searches, or heuristics by experience.[38] These difficulties in feature engineering and training process hinder the wide application of machine learning among nonexpert users."
    }, {
      "heading" : "3. New Trends of Machine Learning in Nanomaterials Discovery and Design",
      "text" : "With recent progress in characterization techniques, nanomaterials database infrastructure, big data, computational capabilities, and mathematical algorithms, some new features of machine learning in nanomaterials science have appeared, which are summarized as follows."
    }, {
      "heading" : "3.1. Automated Feature Engineering",
      "text" : "Most of previous research works use the abovementioned process (Figure 2a) to predict the nanomaterials performance, where feature engineering is indispensable, but difficult and expensive.[16,54] This working paradigm can be regarded as the first-generation approach. With the emergence of deep learning algorithms, automated feature engineering becomes possible in recent years. Unlike traditional machine learning algorithms, deep learning distinguishes itself by using a series of nonlinear functions that are hierarchical cascade. The nonlinear function\nin each level learns to transform its input data into an abstract and composite representation (features) that serves as input for the latter layers. Ultimately, deep learning algorithms are capable of automatically developing their own set of internal features that are relevant to optimally predict the desired output. Chemception, as a deep convolutional neural network (CNN), has been developed to predict the chemical properties of materials, such as toxicity, activity, and solvation properties, by just using the images of 2D drawings of molecules.[43] Without providing the human-driven feature engineering step, Chemception can directly learn a range of distinct features from the raw 2D images. Similarly, a common framework called message passing neural networks (MPNNs) has been also developed for quantum chemistry by eliminating human-expert feature engineering.[44] Automated feature engineering would significantly minimize the amount of domain knowledge used in training model, and accelerate its application among nonexpert users. It would be particularly useful in cases where there is limited understanding about the raw nanomaterials (especially when nanomaterials graphs are available), potentially leading to the revolution of nanomaterials. Machine learning system with automated feature engineering can be regarded as the next-generation paradigm in nanomaterials domain (Figure 2b)."
    }, {
      "heading" : "3.2. Learning from Multidimensional Characterization",
      "text" : "In the early years, input parameters in machine learning are usually limited to the obvious physical and chemical properties, such as dimension, roughness, Young’s modulus, resistivity,\nSmall Methods 2019, 1900025\nFigure 2. Evolution of the workflow of machine learning in nanomaterials discovery and design. a) First-generation approach. In this paradigm, there are two main steps: feature engineering from raw database to descriptors; model building from descriptors to target model. b) Second-generation approach. The key characteristic that distinguishes itself from first-generation approach is eliminating human-expert feature engineering, which can directly learn from raw nanomaterials.\n© 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim1900025 (4 of 7)\nand permittivity, which are simple and interpretable. Progress in high-resolution imaging techniques, for example, scanning transmission electron microscopy (STEM), cryo-electron microscopy (Cryo-EM), and atomic force microscopy (AFM), allows the direct visualization of the morphology and structure of nanomaterials at atomic level. These atomically resolved images offer more effective inputs for guiding nanomaterials design, as they reveal considerable underlying information which is often spatially distributed and multidimensional.[55] Moreover, raw molecular graphs can also provide insight into physical and chemical behavior of materials, which have been regarded as the promising input parameters to predict the quantum mechanical properties of small organic molecules.[44] With the further development of characterization techniques and mathematical algorithms, machine learning system in nanomaterials could learn from much richer data modalities to enhance the prediction performance of models."
    }, {
      "heading" : "3.3. End-to-End Research Methodology",
      "text" : "The enormous knowledge that already exists in scientific literature and websites provides huge information to researchers for guiding nanomaterials design. To make or optimize an appropriate experimental recipe, in conventional procedures, researchers have to read through hundreds or thousands of relevant papers, and manually identify and analyze the information that produces the materials with desired properties.[31] The difficulties and required efforts in navigating the historical knowledge are unprecedentedly increasing due to the proliferation of journals, articles, and databases. One promising approach to release the human labor is utilizing text mining by computer machine to identify and extract the information from unstructured text sources. With recent advances in text mining and full-text publisher application programming interfaces, automated text extraction platforms have been developed, which can automatically retrieve, extract, and sort the relevant information into a structured form (database), or transfer knowledge between domains.[56–58] For example, Kim et al. recently demonstrated a workflow of automatically compiling nanomaterial synthesis parameters across tremendous amounts of scientific literature.[45] Via the text mining, the synthesis conditions (e.g., sintering temperature and stirring speed) of various metal oxides from more than 12 000 articles were codified into a specialized database that serves as the machine learning model for predicting the nanomaterial properties. This enables an end-to-end research\nSmall Methods 2019, 1900025\n© 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim1900025 (5 of 7)\nmethodology to pore through the previous scientific literature to deduce recipes for guiding the nanomaterial design."
    }, {
      "heading" : "4. Technical Challenges",
      "text" : "Although machine learning is expected to revolutionize nanomaterial science, there are many technical challenges to be addressed in order to achieve fruitful achievements. Firstly, a training-application gap lies between training data and target. As most of databases are specialized to address case-by-case issues, a new one typically requires to be constructed for individual study due to the target mismatch issue. The individual database is barely translated to compilation from the existing ones. In addition, the quality of training data is hard to control because the nanomaterials data are collected from different research institutions and organizations, which more or less introduce selection bias and noise.\nModel interpretability is also a crucial challenge that is widely discussed in machine learning. Machine learning models can perform better than human in some specialized tasks, but the knowledge learned by such models is often difficult to understand. In most cases, we really know very little about how the model operates from the inputs to outputs, or what is the specific knowledge learned by each layer for\ndeep neural networks. It is essentially a black box that links the inputs and outputs in machine learning, which hinders users from identifying the weakness of training models and evaluating their confidence. Hence, it is difficult to transfer the learned knowledge from a specialized task to other relevant tasks, although there are possibly similar essential arbitrations among them, especially in nanomaterials. To date, there is still lack of an effective methodology to address this issue, although some efforts have been devoted into exploring the working mechanism of image recognition models by using the visualization of the convolution filters, or saliency maps.[59,60]\nMoreover, other common problems in machine learning system, such as improving the generalization ability and computational efficiency, need to be resolved when building a practical model. In addition, to better utilize nanomaterials, developing the flexible and transferrable descriptors that can represent nanomaterials well is also urgent and challenging."
    }, {
      "heading" : "5. Perspectives",
      "text" : "Using machine learning approaches, recent significant achievements have been made in discovering new nanomaterials, and predicting nanomaterials properties, such as morphology,\nSmall Methods 2019, 1900025\nFigure 3. Perspectives of the further research directions. Experimental, theoretical and algorithmic methodologies need to work interactively with each other to achieve an autonomous nanomaterials system. a) Scanning probe lithography. Reproduced with permission.[65] Copyright 2016, AAAS. b) Cantilever-free scanning probe lithography. Reproduced with permission.[62] Copyright 2019, American Chemical Society. c) Nanocombinatorics. Reproduced with permission.[65] Copyright 2016, AAAS. d) Nano assembly. Reproduced with permission.[66] Copyright 2002, Nature Publishing Group. e) Molecular dynamics. f) Density functional theory. Reproduced with permission.[51] Copyright 2017, American Chemical Society. g) Convolution visualization. Reproduced with permission.[9] Copyright 2018, Nature Publishing Group. h) One-shot learning. Reproduced with permission.[68] Copyright 2015, AAAS.\n© 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim1900025 (6 of 7)\nSmall Methods 2019, 1900025\ntoxicity, activity, energy difference, and defect state. Machine learning has shown a strong capability of accelerating nanomaterials development, which would make researchers release from the sophisticated research task. However, there still remains a long way toward the fully autonomous system for intelligent nanomaterials research. Herein, we propose further research directions (Figure 3) that could contribute to such an autonomous nanomaterials system.\n(1) Machine learning is a data-driven learning approach which typically requires huge amount of training data to achieve the desired performance. Nanocombinatorics, an emerging study methodology of materials via massive parallelization of experimental conditions at the nanoscopic scale, provides a fast and reliable way to produce a mass of high-quality training data for machine learning.[61–64] In nanocombinatorics, a nanocombinatorial library is typically generated by using advanced methodologies, such as scanning probe litho graphy (SPL), cantilever-free SPL, and nano assembly.[62,64–67] These nanocombinatorial libraries with sufficient variety and complexity would be the valuable resources for machine learning. (2) With the exception of intentionally increasing the amount of training data, an alternative approach to facilitate machine learning in nanomaterials is to highly efficiently train the model on a small database. In the tasks of character recognition and drug discovery, one-shot learning methods have been used to resolve the issue of the small amount of training data.[68,69] It will be urgent and promising to optimize or develop machine learning algorithms that can efficiently train the data on a small database, especially when the amount of data is intrinsically small in nanomaterials domain. (3) Machine learning can enhance the existing theoretical computational approaches. The traditional quantum/molecular mechanics, such as density functional theory, molecular dynamics, and Monte Carlo techniques, have been combined with machine learning for materials research.[49,51,70] Coupling with the high throughput computational screening method and evolutionary algorithms, machine learning approach is becoming a powerful tool to design synthesis method and predict complicated properties of nanomaterials, even discover new nanomaterials.\nIn addition, a standard and international nanomaterials ecosystem should be established to validly and reliably assess machine learning for new properties and applications of nanomaterials. We believe a strong AI or artificial general intelligence systems for nanomaterials science will eventually come true in the future."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors thank the financial support from the National Research Foundation (NRF), Prime Minister’s office, Singapore, under its NRF Investigatorship (NRF2016NRF-NRF1001-21), Singapore Ministry of Education (MOE2014-T2-2-140 and MOE2015-T2-2-60), K. C. Wong Education Foundation, and Advanced Manufacturing and Engineering (AME) Programmatic Grant (No. A19A1b0045)."
    }, {
      "heading" : "Conflict of Interest",
      "text" : "The authors declare no conflict of interest."
    }, {
      "heading" : "Keywords",
      "text" : "artificial intelligence (AI), machine learning, nanomaterials, nanomaterials informatics\nReceived: January 9, 2019 Published online:\n[1] Y. LeCun, Y. Bengio, G. Hinton, Nature 2015, 521, 436. [2] A. Krizhevsky, I. Sutskever, G. Hinton, Adv. Neural Inf. Process. Syst.,\nNeural Information Processing Systems Foundation, Inc., Lake Tahoe, USA 2012, p. 1090. [3] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, D. Hassabis, Nature 2016, 529, 484. [4] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, Y. Chen, T. Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, D. Hassabis, Nature 2017, 550, 354. [5] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, S. Thrun, Nature 2017, 542, 115. [6] G. Carleo, M. Troyer, Science 2017, 355, 602. [7] G. B. Goh, N. O. Hodas, A. Vishnu, J. Comput. Chem. 2017, 38,\n1291. [8] M. Wainberg, D. Merico, A. Delong, B. J. Frey, Nat. Biotechnol. 2018,\n36, 829. [9] K.-H. Yu, A. L. Beam, I. S. Kohane, Nat. Biomed. Eng. 2018, 2, 719.\n[10] P. S. Lee, X. Chen, Small 2014, 10, 3432. [11] H. Cheng, N. Yang, Q. Lu, Z. Zhang, H. Zhang, Adv. Mater.\n2018, 30, 1707189. [12] Y. Tang, Y. Zhang, J. Deng, J. Wei, H. Le Tam, B. K. Chandran,\nZ. Dong, Z. Chen, X. Chen, Adv. Mater. 2014, 26, 6111. [13] M. Wang, W. Wang, W. R. Leow, C. Wan, G. Chen, Y. Zeng, J. Yu,\nY. Liu, P. Cai, H. Wang, D. Ielmini, X. Chen, Adv. Mater. 2018, 30, 1802516. [14] M.-K. Tsang, Y.-T. Wong, J. Hao, Small Methods 2018, 2, 1700265. [15] C. Wan, G. Chen, Y. Fu, M. Wang, N. Matsuhisa, S. Pan, L. Pan,\nH. Yang, Q. Wan, L. Zhu, X. Chen, Adv. Mater. 2018, 30, 1801291. [16] Y. Liu, T. Zhao, W. Ju, S. Shi, J. Materiomics 2017, 3, 159. [17] P. Cai, X. Zhang, M. Wang, Y. L. Wu, X. Chen, ACS Nano 2018, 12,\n5078. [18] R. Jose, S. Ramakrishna, Appl. Mater. Today 2018, 10, 127. [19] S. Panneerselvam, S. Choi, Int. J. Mol. Sci. 2014, 15, 7158. [20] R. S. Ruoff, D. S. Tse, R. Malhotra, D. C. Lorents, J. Phys. Chem.\n1993, 97, 3379. [21] V. Simon, J. Gasteiger, J. Zupan, J. Am. Chem. Soc. 1993, 115, 9148. [22] A. Kukovecz, M. Smolik, S. N. Bokova, E. Obraztsova, H. Kataura,\nY. Achiba, H. Kuzmany, 17th Int. Winterschool Euroconf. on Electronic Properties of Novel Materials, American Institute of Physics, New York, USA 2003, p. 211. [23] R. Y. Sato-Berru, E. V. Basiuk, J. M. Saniger, J. Raman Spectrosc. 2006, 37, 1302. [24] R. Hamzaoui, M. Cherigui, S. Guessasma, O. ElKedim, N. Fenineche, Mater. Sci. Eng., B 2009, 163, 17. [25] M. A. Dobrovolskaia, D. R. Germolec, J. L. Weaver, Nat. Nanotechnol. 2009, 4, 411.\n© 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim1900025 (7 of 7)\nSmall Methods 2019, 1900025\n[26] G. Pyrgiotakis, O. E. Kundakcioglu, P. Pardalos, B. Moudgil, J. Raman Spectrosc. 2011, 42, 1222. [27] V. C. Epa, F. R. Burden, C. Tassa, R. Weissleder, S. Shaw, D. A. Winkler, Nano Lett. 2012, 12, 5808. [28] F. Amato, J. L. Gonzalez-Hernandez, J. Havel, Talanta 2012, 93, 72. [29] M. Maghsoudi, M. Ghaedi, A. Zinali, A. M. Ghaedi, M. H. Habibi,\nSpectrochim. Acta A Mol. Biomol. Spectrosc. 2015, 134, 1. [30] D. K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarelli,\nT. Hirzel, A. Aspuru-Guzik, R. P. Adams, Adv. Neural Inf. Process. Syst., Neural Information Processing Systems Foundation, Inc., Montreal, Canada 2015, p. 2224. [31] E. Oh, R. Liu, A. Nel, K. B. Gemill, M. Bilal, Y. Cohen, I. L. Medintz, Nat. Nanotechnol. 2016, 11, 479. [32] B. Sun, M. Fernandez, A. S. Barnard, J. Chem. Inf. Model. 2017, 57, 2413. [33] K. T. Schutt, F. Arbabzadah, S. Chmiela, K. R. Muller, A. Tkatchenko, Nat. Commun. 2017, 8, 13890. [34] Z. Zhou, X. Li, R. N. Zare, ACS Cent. Sci. 2017, 3, 1337. [35] Q. Zhu, A. Samanta, B. Li, R. E. Rudd, T. Frolov, Nat. Commun.\n2018, 9, 467. [36] S. S. Kalantre, J. P. Zwolak, S. Ragole, X. Wu, N. M. Zimmerman,\nJ. M. D. Stewart, J. M. Taylor, npj Quantum Inform. 2019, 5, 6. [37] B. Sanchez-Lengeling, A. Aspuru-Guzik, Science 2018, 361, 360. [38] K. T. Butler, D. W. Davies, H. Cartwright, O. Isayev, A. Walsh, Nature\n2018, 559. [39] Y. Marcus, J. Phys. Chem. B 1997, 101, 8617. [40] M. A. Al-Khedher, C. Pezeshki, J. L. McHale, F. J. Knorr, Nanotech-\nnology 2007, 18, 355703. [41] K. Sarkar, M. B. Ghalia, Z. Wu, S. C. Bose, J. Mater. Process. Technol.\n2009, 209, 3156. [42] J. Timoshenko, D. Lu, Y. Lin, A. I. Frenkel, J. Phys. Chem. Lett. 2017,\n8, 5091. [43] G. B. Goh, C. Siegel, A. Vishnu, N. O. Hodas, N. Baker, arXiv:\n1706.06689, 2017. [44] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, G. E. Dahl, Inter-\nnational Conference on Machine Learning (ICML), Proceedings of Machine Learning Research, Sydney, Australia 2017, p. 1263. [45] E. Kim, K. Huang, A. Saunders, A. McCallum, G. Ceder, E. Olivetti, Chem. Mater. 2017, 29, 9436. [46] X. Jiang, Z. Tan, L. Lin, J. He, C. He, B. D. Thackray, Y. Zhang, J. Ye, Small Methods 2018, 2, 1800182. [47] W. Xie, C. Herrmann, K. Kompe, M. Haase, S. Schlucker, J. Am. Chem. Soc. 2011, 133, 19302.\n[48] A. Maksov, O. Dyck, K. Wang, K. Xiao, D. B. Geohegan, B. G. Sumpter, R. K. Vasudevan, S. Jesse, S. V. Kalinin, M. Ziatdinov, npj Comput. Mater. 2019, 5, 12. [49] Y. Huang, Y. Chen, T. Cheng, L.-W. Wang, W. A. Goddard, ACS Energy Lett. 2018, 3, 2983. [50] M. Fernandez, H. Barron, A. S. Barnard, RSC Adv. 2017, 7, 48962. [51] R. Jinnouchi, R. Asahi, J. Phys. Chem. Lett. 2017, 8, 4279. [52] N. Artrith, A. M. Kolpak, Nano Lett. 2014, 14, 2670. [53] N. Artrith, A. M. Kolpak, Comput. Mater. Sci. 2015, 110, 20. [54] S. Ramakrishna, T.-Y. Zhang, W.-C. Lu, Q. Qian, J. S. C. Low,\nJ. H. R. Yune, D. Z. L. Tan, S. Bressan, S. Sanvito, S. R. Kalidindi, J. Intell. Manuf. 2018, 1. [55] S. V. Kalinin, B. G. Sumpter, R. K. Archibald, Nat. Mater. 2015, 14, 973. [56] L. Hawizy, D. M. Jessop, N. Adams, P. M. Rust, J. Cheminform. 2011, 3, 1. [57] M. C. Swain, J. M. Cole, J. Chem. Inf. Model. 2016, 56, 1894. [58] D. E. Jones, S. Igo, J. Hurdle, J. C. Facelli, PLoS One 2014, 9, e83932. [59] M. D. Zeiler, R. Fergus, European Conference on Computer Vision\n(ECCV), Springer, Zurich, Switzerland 2014, p. 818. [60] K. Simonyan, A. Vedaldi, A. Zisserman, International Conference on\nLearning Representations (ICLR), Banff, Canada 2014, p. 1. [61] L. Huang, P. C. Chen, M. Liu, X. Fu, P. Gordiichuk, Y. Yu,\nC. Wolverton, Y. Kang, C. A. Mirkin, Proc. Natl. Acad. Sci. U. S. A. 2018, 115, 3764. [62] K. A. Brown, J. L. Hedrick, D. J. Eichelsdoerfer, C. A. Mirkin, ACS Nano 2019, 13, 8. [63] L. R. Giam, M. D. Massich, L. Hao, L. S. Wong, C. C. Mader, C. A. Mirkin, Proc. Natl. Acad. Sci. U. S. A. 2012, 109, 4377. [64] E. J. Kluender, J. L. Hedrick, K. A. Brown, R. Rao, B. Meckes, J. S. Du, L. M. Moreau, B. Maruyama, C. A. Mirkin, Proc. Natl. Acad. Sci. U. S. A. 2019, 116, 40. [65] P. C. Chen, X. Liu, J. L. Hedrick, Z. Xie, S. Wang, Q. Y. Lin, M. C. Hersam, V. P. Dravid, C. A. Mirkin, Science 2016, 352, 1565. [66] R. A. McMillan, C. D. Paavola, J. Howard, S. L. Chan, N. J. Zaluzec, J. D. Trent, Nat. Mater. 2002, 1, 247. [67] S. Mann, Nat. Mater. 2009, 8, 781. [68] B. M. Lake, R. Salakhutdinov, J. B. Tenenbaum, Science 2015, 350,\n1332. [69] H. Altae-Tran, B. Ramsundar, A. S. Pappu, V. Pande, ACS Cent. Sci.\n2017, 3, 283. [70] L. Shen, W. Yang, J. Chem. Theory Comput. 2018, 14, 1442."
    } ],
    "references" : [ {
      "title" : "Chem",
      "author" : [ "G.B. Goh", "N.O. Hodas", "A. Vishnu", "J. Comput" ],
      "venue" : "2017, 38,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1291
    }, {
      "title" : "Inf",
      "author" : [ "B. Sun", "M. Fernandez", "A.S. Barnard", "J. Chem" ],
      "venue" : "Model. 2017, 57,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2413
    }, {
      "title" : "Sci",
      "author" : [ "Z. Zhou", "X. Li", "R.N. Zare", "ACS Cent" ],
      "venue" : "2017, 3,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 1337
    }, {
      "title" : "Inf",
      "author" : [ "M.C. Swain", "J.M. Cole", "J. Chem" ],
      "venue" : "Model. 2016, 56,",
      "citeRegEx" : "57",
      "shortCiteRegEx" : null,
      "year" : 1894
    }, {
      "title" : "Theory Comput",
      "author" : [ "L. Shen", "W. Yang", "J. Chem" ],
      "venue" : "2018, 14,",
      "citeRegEx" : "70",
      "shortCiteRegEx" : null,
      "year" : 1442
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Especially with the increasing chemical complexity (Lipinski virtual chemical space reaching up to 1060), the prediction of new nanomaterials and properties is unreachable by using these two traditional approaches.[7,17] Hence, there is an urgent need to develop a new paradigm with both time- and performance-efficiency for nanomaterials science.",
      "startOffset" : 214,
      "endOffset" : 220
    }, {
      "referenceID" : 1,
      "context" : "[20–37,39–53] In the general process of machine learning, feature engineering is critical to guarantee the performance of models, because only the relevant features are meaningful for the construction of prediction models.[32,38] However, the selection of most appropriate features is quite challenging due to the requirements of deep insight into both domain-expert know ledge and the implementation of learning algorithms, which is a hot topic of current research.",
      "startOffset" : 222,
      "endOffset" : 229
    }, {
      "referenceID" : 1,
      "context" : "Electron transfer property of Ag NP: Reproduced with permission.[32] Copyright 2017, American Chemical Society.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 2,
      "context" : "Optimizing chemical reactions: Reproduced with permission under the terms of the Standard ACS AuthorChoice/Editors’ Choice license.[34] Copyright 2017, American Chemical Society.",
      "startOffset" : 131,
      "endOffset" : 135
    } ],
    "year" : 2019,
    "abstractText" : "DOI: 10.1002/smtd.201900025 and applications (Figure 1).[20–37] Although machine learning has shown the capabilities of making predictions with little human input, high time-efficiency and performance-efficiency, it also creates new challenges in guaranteeing the prediction accuracy for nanomaterials science. In this essay, we focus on the new trends and features of machine learning in nanomaterials discovery and design, which could promote nanomaterials development. The challenges and perspectives of machine learning in predicting the discovery of new nanomaterials and the relationships between structure and property are identified and discussed. We hope this essay could give readers some inspiration for further research and applications of machine learning in nanomaterials.",
    "creator" : "Adobe InDesign CS6 (Macintosh)"
  }
}